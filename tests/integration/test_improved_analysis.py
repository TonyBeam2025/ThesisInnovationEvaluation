#!/usr/bin/env python3
import pytest
pytest.skip("integration tests require manual setup (API keys, large data)", allow_module_level=True)
from tests.integration import PROJECT_ROOT
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ”¹è¿›åçš„ç« èŠ‚åˆ†æåŠŸèƒ½
"""

import sys
import os
sys.path.append('src')

from thesis_inno_eval.extract_sections_with_ai import ThesisExtractorPro

def test_improved_chapter_analysis():
    """æµ‹è¯•æ”¹è¿›åçš„ç« èŠ‚åˆ†æåŠŸèƒ½"""
    print("ğŸ”§ æµ‹è¯•æ”¹è¿›åçš„ç« èŠ‚åˆ†æåŠŸèƒ½")
    print("=" * 80)
    
    # æµ‹è¯•è®¡ç®—æœºåº”ç”¨æŠ€æœ¯è®ºæ–‡
    extractor = ThesisExtractorPro()
    doc_path = "data/input/1_è®¡ç®—æœºåº”ç”¨æŠ€æœ¯_17211204005-è‹æ…§å©§-åŸºäºMLPå’ŒSepCNNæ¨¡å‹çš„è—æ–‡æ–‡æœ¬åˆ†ç±»ç ”ç©¶ä¸å®ç°-è®¡ç®—æœºåº”ç”¨æŠ€æœ¯-ç¾¤è¯º.docx"
    
    print(f"ğŸ“ æµ‹è¯•æ–‡ä»¶: {os.path.basename(doc_path)}")
    
    try:
        # å…ˆè¯»å–æ–‡æ¡£æ–‡æœ¬
        print(f"\nğŸ“– è¯»å–æ–‡æ¡£å†…å®¹...")
        from thesis_inno_eval.extract_sections_with_ai import extract_text_from_word
        text = extract_text_from_word(doc_path)
        print(f"   æ–‡æ¡£é•¿åº¦: {len(text)} å­—ç¬¦")
        
        # å•ç‹¬æµ‹è¯•ç›®å½•æå–å’Œç« èŠ‚åˆ†æ
        print(f"\nğŸ” æµ‹è¯•ç›®å½•æå–å’Œç« èŠ‚åˆ†æ...")
        toc_analysis = extractor._extract_and_analyze_toc(text, doc_path)
        
        print(f"\nğŸ“Š ç›®å½•åˆ†æç»“æœ:")
        print(f"  - æå–æ–¹æ³•: {toc_analysis.get('extraction_method', 'unknown')}")
        print(f"  - ç½®ä¿¡åº¦: {toc_analysis.get('confidence_score', 0):.3f}")
        print(f"  - æ€»æ¡ç›®æ•°: {toc_analysis.get('total_entries', 0)}")
        print(f"  - æœ€å¤§å±‚çº§: {toc_analysis.get('max_level', 0)}")
        
        # æ˜¾ç¤ºç›®å½•ç»“æ„
        chapters = toc_analysis.get('table_of_contents', [])
        if chapters:
            print(f"\nğŸ“š æå–çš„ç« èŠ‚ç»“æ„ ({len(chapters)} ä¸ª):")
            print("-" * 70)
            for i, chapter in enumerate(chapters, 1):
                level_indent = "  " * (chapter.get('level', 1) - 1)
                title = chapter.get('title', 'Unknown')
                number = chapter.get('number', '')
                section_type = chapter.get('section_type', '')
                confidence = chapter.get('confidence', 0)
                
                print(f"{i:2d}. {level_indent}[L{chapter.get('level', 1)}] {number} {title}")
                print(f"    {level_indent}    ç±»å‹: {section_type}, ç½®ä¿¡åº¦: {confidence:.2f}")
                
                # æµ‹è¯•ç« èŠ‚ç±»å‹åˆ†ç±»
                classified_type = extractor._classify_chapter_type(chapter)
                print(f"    {level_indent}    åˆ†ç±»: {classified_type}")
        
        # æ˜¾ç¤ºç« èŠ‚åˆ†æç»“æœ
        chapter_summaries = toc_analysis.get('chapter_summaries', {})
        if chapter_summaries:
            print(f"\nğŸ§  ç« èŠ‚AIåˆ†æç»“æœ ({len(chapter_summaries)} ä¸ª):")
            print("-" * 70)
            for i, (chapter_title, summary) in enumerate(chapter_summaries.items(), 1):
                print(f"\n{i}. ğŸ“– {chapter_title}")
                print("-" * 50)
                
                if isinstance(summary, dict):
                    print(f"æ‘˜è¦: {summary.get('summary', 'N/A')[:200]}...")
                    print(f"å…³é”®ç‚¹æ•°: {len(summary.get('key_points', []))}")
                    if summary.get('key_points'):
                        for j, point in enumerate(summary.get('key_points', [])[:3], 1):
                            print(f"  {j}. {point}")
                    
                    # æ˜¾ç¤ºå…¶ä»–åˆ†æç»“æœ
                    for key in ['methods', 'results', 'parameters', 'research_trends', 'chapter_type']:
                        if key in summary and summary[key]:
                            print(f"{key}: {summary[key]}")
                else:
                    print(f"å†…å®¹: {str(summary)[:200]}...")
        
        # æ˜¾ç¤ºæ–‡çŒ®ç»¼è¿°åˆ†æ
        lit_analysis = toc_analysis.get('literature_analysis', {})
        if lit_analysis:
            print(f"\nğŸ“š æ–‡çŒ®ç»¼è¿°åˆ†æ:")
            print("-" * 50)
            for key, value in lit_analysis.items():
                if value and isinstance(value, list):
                    print(f"{key}: {value[:3]}")  # åªæ˜¾ç¤ºå‰3ä¸ª
                elif value:
                    print(f"{key}: {str(value)[:100]}...")
        
        # æ˜¾ç¤ºæ–¹æ³•è®ºåˆ†æ
        method_analysis = toc_analysis.get('methodology_analysis', {})
        if method_analysis:
            print(f"\nğŸ”¬ æ–¹æ³•è®ºåˆ†æ:")
            print("-" * 50)
            for key, value in method_analysis.items():
                if value and isinstance(value, list):
                    print(f"{key}: {value[:3]}")
                elif value:
                    print(f"{key}: {str(value)[:100]}...")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        output_file = "improved_chapter_analysis.json"
        try:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                # ç®€åŒ–ç»“æœä»¥ä¾¿JSONåºåˆ—åŒ–
                simplified_result = {}
                for key, value in toc_analysis.items():
                    if isinstance(value, (str, int, float, bool, list, dict)):
                        simplified_result[key] = value
                    else:
                        simplified_result[key] = str(value)
                
                json.dump(simplified_result, f, ensure_ascii=False, indent=2)
            
            print(f"\n è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° {output_file}")
            
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
        
        return toc_analysis
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

if __name__ == "__main__":
    test_improved_chapter_analysis()

"""
æµ‹è¯•ä¸‰ä¸ªå­¦ä½è®ºæ–‡çš„ç›®å½•æå–
éŸ³ä¹ã€é©¬å…‹æ€ä¸»ä¹‰å“²å­¦ã€æ³•å¾‹ç¡•å£«
"""
import pytest
pytest.skip("integration tests require manual setup (API keys, large data)", allow_module_level=True)
from tests.integration import PROJECT_ROOT
import sys
import os
sys.path.append(os.path.join(str(PROJECT_ROOT), 'src'))

from thesis_inno_eval.ai_toc_extractor import AITocExtractor
import json

def test_document(doc_path, doc_name):
    """æµ‹è¯•å•ä¸ªæ–‡æ¡£çš„ç›®å½•æå–"""
    print(f"\n{'='*80}")
    print(f"ğŸ“– æµ‹è¯•æ–‡æ¡£: {doc_name}")
    print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {os.path.basename(doc_path)}")
    print(f"{'='*80}")
    
    if not os.path.exists(doc_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {doc_path}")
        return
    
    try:
        # åˆå§‹åŒ–æå–å™¨
        extractor = AITocExtractor()
        
        # æå–ç›®å½•
        print("ğŸ”„ å¼€å§‹æå–ç›®å½•...")
        result = extractor.extract_toc(doc_path)
        
        if result and result.entries:
            # ç»Ÿè®¡å„ç±»ç« èŠ‚
            chapters = []
            special_sections = []
            post_references = []
            level2_sections = []
            level3_sections = []
            
            # åˆ†ç±»ç»Ÿè®¡
            for entry in result.entries:
                if hasattr(entry, 'section_type'):
                    if entry.section_type in ['traditional_chapter', 'numeric_chapter', 'english_chapter', 'chapter']:
                        chapters.append(entry)
                    elif entry.section_type in ['abstract', 'references', 'conclusion']:
                        special_sections.append(entry)
                    elif entry.section_type in ['achievements', 'acknowledgment', 'author_profile']:
                        post_references.append(entry)
                    elif entry.section_type == 'level2_section':
                        level2_sections.append(entry)
                    elif entry.section_type == 'level3_section':
                        level3_sections.append(entry)
            
            print(f"\nğŸ“Š æå–ç»“æœç»Ÿè®¡:")
            print(f"   ğŸ“š æ­£æ–‡ç« èŠ‚: {len(chapters)}ä¸ª")
            print(f"   ğŸ“„ äºŒçº§ç« èŠ‚: {len(level2_sections)}ä¸ª")
            print(f"   ğŸ“ ä¸‰çº§ç« èŠ‚: {len(level3_sections)}ä¸ª")
            print(f"   ğŸ” ç‰¹æ®Šç« èŠ‚: {len(special_sections)}ä¸ª") 
            print(f"   ğŸ“– å‚è€ƒæ–‡çŒ®åç« èŠ‚: {len(post_references)}ä¸ª")
            print(f"   ğŸ“ˆ æ€»æ¡ç›®: {result.total_entries}ä¸ª")
            print(f"   ğŸ¯ ç½®ä¿¡åº¦: {result.confidence_score:.2f}")
            print(f"   ğŸ¤– æå–æ–¹æ³•: {result.extraction_method}")
            
            # æ˜¾ç¤ºæ­£æ–‡ç« èŠ‚
            if chapters:
                print(f"\nğŸ“š æ­£æ–‡ç« èŠ‚è¯¦æƒ…:")
                for i, chapter in enumerate(chapters, 1):
                    print(f"   {i}. ã€{chapter.number}ã€‘ {chapter.title}")
                    print(f"      é¡µç : {chapter.page} | ç½®ä¿¡åº¦: {chapter.confidence:.2f}")
            
            # æ˜¾ç¤ºç‰¹æ®Šç« èŠ‚
            if special_sections:
                print(f"\nğŸ” ç‰¹æ®Šç« èŠ‚è¯¦æƒ…:")
                for i, section in enumerate(special_sections, 1):
                    print(f"   {i}. ã€{section.section_type}ã€‘ {section.title}")
                    print(f"      é¡µç : {section.page} | ç½®ä¿¡åº¦: {section.confidence:.2f}")
            
            # æ˜¾ç¤ºå‚è€ƒæ–‡çŒ®åç« èŠ‚
            if post_references:
                print(f"\nğŸ“– å‚è€ƒæ–‡çŒ®åç« èŠ‚è¯¦æƒ…:")
                for i, section in enumerate(post_references, 1):
                    print(f"   {i}. ã€{section.section_type}ã€‘ {section.title}")
                    print(f"      é¡µç : {section.page} | ç½®ä¿¡åº¦: {section.confidence:.2f}")
            else:
                print(f"\nâš ï¸  æœªæ£€æµ‹åˆ°å‚è€ƒæ–‡çŒ®åç« èŠ‚")
            
            # æ˜¾ç¤ºç»“æ„æ¦‚è§ˆ
            print(f"\nğŸ—ï¸  æ–‡æ¡£ç»“æ„æ¦‚è§ˆ:")
            level_counts = {}
            for entry in result.entries:
                level = entry.level
                if level not in level_counts:
                    level_counts[level] = 0
                level_counts[level] += 1
            
            for level in sorted(level_counts.keys()):
                print(f"   ç¬¬{level}çº§: {level_counts[level]}ä¸ªæ¡ç›®")
                
            print(f"\n ç›®å½•æå–æˆåŠŸ!")
                
        else:
            print("âŒ æå–å¤±è´¥æˆ–ç»“æœä¸ºç©º")
            
    except Exception as e:
        print(f"âŒ æå–è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    documents = [
        {
            'path': r"c:\MyProjects\thesis_Inno_Eval\data\input\1_éŸ³ä¹_20172001013éŸ©æŸ ç¿ï¼ˆç¡•å£«æ¯•ä¸šè®ºæ–‡ï¼‰.docx",
            'name': "éŸ³ä¹å­¦ç¡•å£«è®ºæ–‡"
        },
        {
            'path': r"c:\MyProjects\thesis_Inno_Eval\data\input\1_é©¬å…‹æ€ä¸»ä¹‰å“²å­¦86406_010101_81890101_LW.docx", 
            'name': "é©¬å…‹æ€ä¸»ä¹‰å“²å­¦å­¦ä½è®ºæ–‡"
        },
        {
            'path': r"c:\MyProjects\thesis_Inno_Eval\data\input\æ³•å¾‹ç¡•å£«_2018213020_ç‹çºªé”‹_å­¦ä½è®ºæ–‡.docx",
            'name': "æ³•å¾‹ç¡•å£«å­¦ä½è®ºæ–‡"
        }
    ]
    
    print("ğŸš€ å¼€å§‹æµ‹è¯•ä¸‰ä¸ªå­¦ä½è®ºæ–‡çš„ç›®å½•æå–")
    print("ğŸ“‹ åŒ…æ‹¬: éŸ³ä¹å­¦ã€é©¬å…‹æ€ä¸»ä¹‰å“²å­¦ã€æ³•å¾‹ç¡•å£«")
    
    for doc_info in documents:
        if doc_info['path'].endswith('.doc'):
            print(f"\n{'='*80}")
            print(f"ğŸ“– æµ‹è¯•æ–‡æ¡£: {doc_info['name']}")
            print(f"ğŸ“ æ–‡ä»¶è·¯å¾„: {os.path.basename(doc_info['path'])}")
            print(f"{'='*80}")
            print("âŒ .docæ ¼å¼ä¸æ”¯æŒï¼Œè¯·å…ˆè½¬æ¢ä¸º.docxæ ¼å¼")
            continue
            
        test_document(doc_info['path'], doc_info['name'])
    
    print(f"\n{'='*80}")
    print(" æµ‹è¯•å®Œæˆ")
    print("ğŸ’¡ æç¤º: å¦‚å‘ç°.docæ–‡ä»¶ï¼Œè¯·æ‰‹åŠ¨è½¬æ¢ä¸º.docxæ ¼å¼åé‡æ–°æµ‹è¯•")
    print(f"{'='*80}")

if __name__ == "__main__":
    main()

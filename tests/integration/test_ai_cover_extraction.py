#!/usr/bin/env python3
"""
ä¸“é—¨æµ‹è¯•AIæ™ºèƒ½è¯†åˆ«å°é¢ä¿¡æ¯
è§£å†³å¯¼å…¥é—®é¢˜ï¼Œç›´æ¥ä½¿ç”¨AIè¿›è¡Œæ™ºèƒ½è¯†åˆ«
"""
import pytest
pytest.skip("integration tests require manual setup (API keys, large data)", allow_module_level=True)
from tests.integration import PROJECT_ROOT

import sys
import os
sys.path.insert(0, os.path.join(str(PROJECT_ROOT), 'src'))

import json
from thesis_inno_eval.extract_sections_with_ai import extract_text_from_word

# ç›´æ¥å¯¼å…¥AIå®¢æˆ·ç«¯
try:
    from thesis_inno_eval.gemini_client import get_ai_client
    AI_AVAILABLE = True
except ImportError:
    AI_AVAILABLE = False

def extract_cover_with_ai(cover_text: str) -> dict:
    """ä½¿ç”¨AIç›´æ¥æ™ºèƒ½è¯†åˆ«å°é¢ä¿¡æ¯"""
    
    if not AI_AVAILABLE:
        print("âŒ AIå®¢æˆ·ç«¯ä¸å¯ç”¨")
        return {}
    
    try:
        ai_client = get_ai_client()
        
        prompt = f"""
è¯·ä»ä»¥ä¸‹å­¦ä½è®ºæ–‡å°é¢å†…å®¹ä¸­æå–è®ºæ–‡çš„åŸºæœ¬ä¿¡æ¯ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ï¼Œåªæå–ç¡®å®å­˜åœ¨çš„ä¿¡æ¯ï¼Œä¸è¦ç¼–é€ ï¼š

å°é¢å†…å®¹ï¼š
{cover_text[:2000]}

è¯·æå–ä»¥ä¸‹å­—æ®µï¼ˆå¦‚æœæŸä¸ªå­—æ®µä¸å­˜åœ¨ï¼Œè¯·è®¾ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰ï¼š
{{
  "ThesisNumber": "å­¦å·",
  "ChineseTitle": "ä¸­æ–‡è®ºæ–‡æ ‡é¢˜",
  "EnglishTitle": "è‹±æ–‡è®ºæ–‡æ ‡é¢˜", 
  "ChineseAuthor": "ä½œè€…ä¸­æ–‡å§“å",
  "EnglishAuthor": "ä½œè€…è‹±æ–‡å§“å",
  "ChineseUniversity": "ä¸­æ–‡å­¦æ ¡åç§°",
  "EnglishUniversity": "è‹±æ–‡å­¦æ ¡åç§°",
  "DegreeLevel": "å­¦ä½çº§åˆ«ï¼ˆå¦‚ï¼šåšå£«ã€ç¡•å£«ï¼‰",
  "ChineseMajor": "ä¸­æ–‡ä¸“ä¸šåç§°",
  "EnglishMajor": "è‹±æ–‡ä¸“ä¸šåç§°",
  "College": "å­¦é™¢åç§°",
  "ChineseSupervisor": "ä¸­æ–‡å¯¼å¸ˆå§“å",
  "EnglishSupervisor": "è‹±æ–‡å¯¼å¸ˆå§“å",
  "DefenseDate": "ç­”è¾©æ—¥æœŸ",
  "SubmissionDate": "æäº¤æ—¥æœŸ"
}}

æ³¨æ„ï¼š
- åªæå–æ˜ç¡®å­˜åœ¨çš„ä¿¡æ¯ï¼Œä¸è¦æ¨æµ‹
- å§“åä¸è¦åŒ…å«"å§“åï¼š"ç­‰æ ‡ç­¾
- å­¦æ ¡åç§°ä¸è¦åŒ…å«"å­¦ä½æˆäºˆå•ä½ï¼š"ç­‰æ ‡ç­¾
- æ ‡é¢˜è¦å®Œæ•´ï¼Œä¸è¦åŒ…å«æ—¶é—´æˆ³ç­‰æ— å…³ä¿¡æ¯
- æ—¥æœŸæ ¼å¼ä¸ºYYYY-MM-DDï¼Œå¦‚æœåªæœ‰å¹´ä»½åˆ™ä¸ºYYYY

è¿”å›JSONï¼š"""

        response = ai_client.send_message(prompt)
        if response and response.content:
            # æå–JSONå†…å®¹
            content = response.content.strip()
            if content.startswith('```json'):
                content = content[7:]
            if content.endswith('```'):
                content = content[:-3]
            
            metadata = json.loads(content.strip())
            
            # éªŒè¯å’Œæ¸…ç†ç»“æœ
            for key, value in metadata.items():
                if value and isinstance(value, str):
                    metadata[key] = value.strip()
            
            return metadata
        
    except Exception as e:
        print(f"âŒ AIè¯†åˆ«å¤±è´¥: {e}")
        return {}

def test_ai_cover_extraction():
    """æµ‹è¯•AIå°é¢ä¿¡æ¯æå–"""
    
    print("ğŸ§  æµ‹è¯•AIæ™ºèƒ½è¯†åˆ«å°é¢ä¿¡æ¯")
    print("=" * 60)
    
    file_path = "data/input/50286.docx"
    
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return
    
    try:
        # æå–æ–‡æ¡£æ–‡æœ¬
        print("ğŸ“„ æå–æ–‡æ¡£æ–‡æœ¬...")
        text = extract_text_from_word(file_path)
        
        if not text:
            print("âŒ æ–‡æ¡£æ–‡æœ¬æå–å¤±è´¥")
            return
        
        print(f"ğŸ“Š æ–‡æ¡£é•¿åº¦: {len(text):,} å­—ç¬¦")
        
        # ç²¾å‡†å®šä½å°é¢åŒºåŸŸ
        print("\nğŸ¯ ç²¾å‡†å®šä½å°é¢åŒºåŸŸ...")
        cover_end_markers = [
            'å­¦ä½è®ºæ–‡ä½¿ç”¨æˆæƒä¹¦',
            'å­¦ä½è®ºæ–‡åŸåˆ›æ€§å£°æ˜',
            'ç‹¬åˆ›æ€§å£°æ˜',
            'ç‰ˆæƒä½¿ç”¨æˆæƒä¹¦',
            'ä¸­æ–‡æ‘˜è¦',
            'æ‘˜è¦',
            'ABSTRACT'
        ]
        
        cover_text = text
        for marker in cover_end_markers:
            pos = text.find(marker)
            if pos > 0:
                cover_text = text[:pos]
                print(f"   å°é¢åŒºåŸŸå®šä½: åœ¨'{marker}'ä¹‹å‰ï¼Œé•¿åº¦ {len(cover_text)} å­—ç¬¦")
                break
        
        # æ˜¾ç¤ºå°é¢å†…å®¹ç‰‡æ®µ
        print(f"\nğŸ“„ å°é¢å†…å®¹ç‰‡æ®µ:")
        print("-" * 40)
        print(cover_text[:500] + "..." if len(cover_text) > 500 else cover_text)
        print("-" * 40)
        
        # ä½¿ç”¨AIæ™ºèƒ½è¯†åˆ«
        print(f"\nğŸ§  ä½¿ç”¨AIæ™ºèƒ½è¯†åˆ«...")
        if AI_AVAILABLE:
            ai_result = extract_cover_with_ai(cover_text)
            
            print(f"\n AIè¯†åˆ«ç»“æœ:")
            print("-" * 40)
            for field, value in ai_result.items():
                status = "" if value else "âŒ"
                print(f"   {status} {field}: {value}")
            
            # ä¿å­˜AIç»“æœ
            output_file = "data/output/50286_ai_cover_extracted_info.json"
            os.makedirs(os.path.dirname(output_file), exist_ok=True)
            
            result_data = {
                'ai_cover_metadata': ai_result,
                'extraction_method': 'ai_intelligent_recognition',
                'extraction_time': '2025-08-20T17:20:00',
                'file_path': file_path
            }
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result_data, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ’¾ AIè¯†åˆ«ç»“æœå·²ä¿å­˜: {output_file}")
            
            # è´¨é‡è¯„ä¼°
            non_empty_count = sum(1 for v in ai_result.values() if v and str(v).strip())
            total_fields = len(ai_result)
            completeness = non_empty_count / total_fields
            
            print(f"\nğŸ“Š AIè¯†åˆ«è´¨é‡è¯„ä¼°:")
            print(f"   æå–å­—æ®µæ•°: {non_empty_count}/{total_fields}")
            print(f"   å®Œæ•´åº¦: {completeness:.1%}")
            print(f"   æ˜¯å¦åŒ…å«æ ‡ç­¾æ–‡å­—: {'å¦' if not any('ï¼š' in str(v) for v in ai_result.values() if v) else 'æ˜¯'}")
            
            return ai_result
        else:
            print("âŒ AIä¸å¯ç”¨ï¼Œè·³è¿‡AIè¯†åˆ«æµ‹è¯•")
        
    except Exception as e:
        print(f"âŒ AIå°é¢æå–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_ai_cover_extraction()

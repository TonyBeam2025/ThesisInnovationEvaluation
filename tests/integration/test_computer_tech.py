#!/usr/bin/env python3
import pytest
pytest.skip("integration tests require manual setup (API keys, large data)", allow_module_level=True)
from tests.integration import PROJECT_ROOT
# -*- coding: utf-8 -*-
"""
æµ‹è¯•è®¡ç®—æœºåº”ç”¨æŠ€æœ¯è®ºæ–‡çš„ç›®å½•æå–
"""

import sys
import os
sys.path.append(str(PROJECT_ROOT))

from src.thesis_inno_eval.ai_toc_extractor import AITocExtractor

def test_computer_tech_thesis():
    """æµ‹è¯•è®¡ç®—æœºåº”ç”¨æŠ€æœ¯è®ºæ–‡ç›®å½•æå–"""
    print("ğŸ–¥ï¸ æµ‹è¯•è®¡ç®—æœºåº”ç”¨æŠ€æœ¯è®ºæ–‡ç›®å½•æå–")
    print("=" * 80)
    
    doc_path = r"c:\MyProjects\thesis_Inno_Eval\data\input\1_è®¡ç®—æœºåº”ç”¨æŠ€æœ¯_17211204005-è‹æ…§å©§-åŸºäºMLPå’ŒSepCNNæ¨¡å‹çš„è—æ–‡æ–‡æœ¬åˆ†ç±»ç ”ç©¶ä¸å®ç°-è®¡ç®—æœºåº”ç”¨æŠ€æœ¯-ç¾¤è¯º.docx"
    print(f"ğŸ“ æ–‡ä»¶: {os.path.basename(doc_path)}")
    
    try:
        print("ğŸ”„ å¼€å§‹æå–ç›®å½•...")
        extractor = AITocExtractor()
        result = extractor.extract_toc(doc_path)
        
        if result and result.entries:
            print(f"\nğŸ“Š æå–ç»“æœ:")
            print(f"  æ€»æ¡ç›®æ•°: {len(result.entries)}")
            print(f"  ç½®ä¿¡åº¦: {result.confidence_score:.2f}")
            print(f"  æå–æ–¹æ³•: {result.extraction_method}")
            
            print(f"\nğŸ“‹ å®Œæ•´ç›®å½•æ¡ç›®åˆ—è¡¨:")
            print("-" * 80)
            
            for i, entry in enumerate(result.entries, 1):
                type_label = f"ã€{entry.section_type}ã€‘" if entry.section_type else "ã€unknownã€‘"
                page_info = f"é¡µç : {entry.page}" if entry.page else "é¡µç : None"
                
                print(f"{i:2d}. {type_label} {entry.title}")
                print(f"     {page_info} | çº§åˆ«: {entry.level}")
            
            # æ£€æŸ¥é¢„æœŸçš„ç« èŠ‚æ˜¯å¦éƒ½å­˜åœ¨
            expected_chapters = [
                "ç¬¬ä¸€ç«  ç»ªè®º",
                "ç¬¬äºŒç«  ç›¸å…³ç†è®ºåŠæŠ€æœ¯", 
                "ç¬¬ä¸‰ç«  åŸºäºMLPæ¨¡å‹çš„è—æ–‡æ–‡æœ¬åˆ†ç±»æ–¹æ³•ç ”ç©¶",
                "ç¬¬å››ç«  åŸºäºSepCNNæ¨¡å‹çš„è—æ–‡æ–‡æœ¬åˆ†ç±»æ–¹æ³•ç ”ç©¶",
                "ç¬¬äº”ç«  è—æ–‡æ–‡æœ¬åˆ†ç±»æ¢ç©¶ä¸å¯¹æ¯”å®éªŒ",
                "ç¬¬å…­ç«  è—æ–‡æ–‡æœ¬åˆ†ç±»ç³»ç»Ÿçš„è®¾è®¡ä¸å®ç°",
                "ç¬¬ä¸ƒç«  æ€»ç»“ä¸å±•æœ›"
            ]
            
            print(f"\nğŸ¯ é¢„æœŸç« èŠ‚æ£€æŸ¥:")
            print("-" * 50)
            
            found_chapters = []
            for expected in expected_chapters:
                found = False
                for entry in result.entries:
                    if expected.replace(" ", "") in entry.title.replace(" ", "") or \
                       any(word in entry.title for word in expected.split() if len(word) > 2):
                        found_chapters.append(entry.title)
                        print(f" æ‰¾åˆ°: {entry.title}")
                        found = True
                        break
                if not found:
                    print(f"âŒ ç¼ºå¤±: {expected}")
            
            # æ£€æŸ¥å­¦æœ¯åç« èŠ‚
            academic_sections = ["å‚è€ƒæ–‡çŒ®", "æ”»è¯»ç¡•å£«å­¦ä½æœŸé—´è·å¾—çš„æˆæœ", "è‡´è°¢"]
            print(f"\nğŸ“– å­¦æœ¯åç« èŠ‚æ£€æŸ¥:")
            print("-" * 50)
            
            for academic in academic_sections:
                found = False
                for entry in result.entries:
                    if academic in entry.title:
                        print(f" æ‰¾åˆ°: {entry.title}")
                        found = True
                        break
                if not found:
                    print(f"âŒ ç¼ºå¤±: {academic}")
                    
            print(f"\nğŸ” åŸå§‹ç›®å½•å†…å®¹é¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰:")
            print("-" * 50)
            print(result.toc_content[:500] + "..." if len(result.toc_content) > 500 else result.toc_content)
                    
        else:
            print("âŒ æå–å¤±è´¥æˆ–ç»“æœä¸ºç©º")
            
    except Exception as e:
        print(f"âŒ æå–è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_computer_tech_thesis()

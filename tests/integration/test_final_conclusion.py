#!/usr/bin/env python3
"""æµ‹è¯•å®Œæ•´çš„ç»“è®ºåˆ†ææµç¨‹"""
import pytest
pytest.skip("integration tests require manual setup (API keys, large data)", allow_module_level=True)
from tests.integration import PROJECT_ROOT

import sys
sys.path.append('./src')
from thesis_inno_eval.extract_sections_with_ai import ThesisExtractorPro
import docx
import json

print('ğŸ§ª æµ‹è¯•å®Œæ•´çš„ç»“è®ºåˆ†ææµç¨‹...')

# è¯»å–æ–‡æ¡£
file_path = './data/input/50193.docx'
doc = docx.Document(file_path)
text = '\n'.join([para.text for para in doc.paragraphs])

# åˆå§‹åŒ–æå–å™¨
extractor = ThesisExtractorPro()

# æµ‹è¯•ç»“è®ºåˆ†æ
conclusion_analysis = extractor._analyze_conclusion_with_ai(text)

print('\nğŸ“Š ç»“è®ºåˆ†æç»“æœ:')
conclusions = conclusion_analysis.get('conclusions', [])
contributions = conclusion_analysis.get('contributions', [])
future_work = conclusion_analysis.get('future_work', [])

print(f'ä¸»è¦ç»“è®º: {len(conclusions)} ä¸ª')
for i, conclusion in enumerate(conclusions, 1):
    print(f'  {i}. {conclusion[:80]}...')

print(f'\nå­¦æœ¯è´¡çŒ®: {len(contributions)} ä¸ª')
for i, contribution in enumerate(contributions, 1):
    print(f'  {i}. {contribution[:80]}...')

print(f'\næœªæ¥å·¥ä½œ: {len(future_work)} ä¸ª')
for i, future in enumerate(future_work, 1):
    print(f'  {i}. {future[:80]}...')

# ä¿å­˜è¯¦ç»†ç»“æœ
with open('./data/output/final_conclusion_analysis.json', 'w', encoding='utf-8') as f:
    json.dump(conclusion_analysis, f, ensure_ascii=False, indent=2)

print('\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ° ./data/output/final_conclusion_analysis.json')

# éªŒè¯ç»“è®ºéƒ¨åˆ†ä¸å†ä¸ºç©º
if conclusions or contributions or future_work:
    print('\nğŸ‰ ç»“è®ºåˆ†æä¿®å¤æˆåŠŸï¼ç»“è®ºéƒ¨åˆ†ä¸å†ä¸ºç©º')
else:
    print('\nâŒ ç»“è®ºåˆ†æä»ç„¶ä¸ºç©ºï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•')

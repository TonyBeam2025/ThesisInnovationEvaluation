#!/usr/bin/env python3
"""
æµ‹è¯•æ”¹è¿›åçš„å°é¢ä¿¡æ¯æå–
é‡ç‚¹éªŒè¯ï¼šç²¾å‡†å®šä½ + AIæ™ºèƒ½è¯†åˆ«
"""
import pytest
pytest.skip("integration tests require manual setup (API keys, large data)", allow_module_level=True)
from tests.integration import PROJECT_ROOT

import sys
import os
sys.path.insert(0, os.path.join(str(PROJECT_ROOT), 'src'))

import json
from thesis_inno_eval.extract_sections_with_ai import extract_text_from_word, ThesisExtractorPro

def test_cover_extraction():
    """æµ‹è¯•å°é¢ä¿¡æ¯æå–"""
    
    print("ğŸ¯ æµ‹è¯•æ”¹è¿›åçš„å°é¢ä¿¡æ¯æå–")
    print("=" * 60)
    
    file_path = "data/input/50286.docx"
    
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return
    
    try:
        # æå–æ–‡æ¡£æ–‡æœ¬
        print("ğŸ“„ æå–æ–‡æ¡£æ–‡æœ¬...")
        text = extract_text_from_word(file_path)
        
        if not text:
            print("âŒ æ–‡æ¡£æ–‡æœ¬æå–å¤±è´¥")
            return
        
        print(f"ğŸ“Š æ–‡æ¡£é•¿åº¦: {len(text):,} å­—ç¬¦")
        
        # ä½¿ç”¨æ”¹è¿›åçš„æå–å™¨
        extractor = ThesisExtractorPro()
        
        # åªæµ‹è¯•å°é¢ä¿¡æ¯æå–
        print("\nğŸ¯ æµ‹è¯•å°é¢ä¿¡æ¯æå–...")
        cover_metadata = extractor._extract_front_metadata(text)
        
        print("\nğŸ“Š å°é¢ä¿¡æ¯æå–ç»“æœ:")
        print("-" * 40)
        
        key_fields = [
            'ThesisNumber', 'ChineseTitle', 'ChineseAuthor', 
            'ChineseUniversity', 'DegreeLevel', 'ChineseMajor',
            'College', 'ChineseSupervisor', 'DefenseDate'
        ]
        
        for field in key_fields:
            value = cover_metadata.get(field, '')
            status = "" if value else "âŒ"
            print(f"   {status} {field}: {value}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ˜æ˜¾çš„é”™è¯¯æ ‡è®°
        print("\nğŸ” é”™è¯¯æ£€æŸ¥:")
        for field, value in cover_metadata.items():
            if value:
                if 'è½¬æ¢æ—¶é—´' in str(value):
                    print(f"   âš ï¸ {field} åŒ…å«è½¬æ¢æ—¶é—´æ ‡è®°: {value}")
                elif field == 'ChineseAuthor' and ('å§“å' in str(value) or len(str(value)) > 10):
                    print(f"   âš ï¸ {field} å¯èƒ½åŒ…å«æ ‡ç­¾æˆ–å¼‚å¸¸: {value}")
                elif field == 'ChineseUniversity' and ('å­¦ä½æˆäºˆå•ä½' in str(value)):
                    print(f"   âš ï¸ {field} åŒ…å«æ ¼å¼æ ‡ç­¾: {value}")
        
        # æ˜¾ç¤ºæ”¹è¿›æ•ˆæœ
        print(f"\nğŸ“ˆ æ”¹è¿›æ•ˆæœå¯¹æ¯”:")
        print(f"   æå–å­—æ®µæ•°: {len([v for v in cover_metadata.values() if v])}/{len(key_fields)}")
        print(f"   æ˜¯å¦åŒ…å«AIæ™ºèƒ½è¯†åˆ«: {'æ˜¯' if extractor.ai_client else 'å¦ï¼ˆä½¿ç”¨æ¨¡å¼åŒ¹é…ï¼‰'}")
        
        # ä¿å­˜ç»“æœ
        output_file = "data/output/50286_cover_extracted_info.json"
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        result_data = {
            'cover_metadata': cover_metadata,
            'extraction_method': 'ai_enhanced' if extractor.ai_client else 'pattern_matching',
            'extraction_time': '2025-08-20T17:15:00',
            'file_path': file_path
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ å°é¢æå–ç»“æœå·²ä¿å­˜: {output_file}")
        
        return cover_metadata
        
    except Exception as e:
        print(f"âŒ å°é¢ä¿¡æ¯æå–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def compare_with_previous():
    """ä¸ä¹‹å‰çš„ç»“æœå¯¹æ¯”"""
    
    print("\nğŸ“Š ä¸ä¹‹å‰ç»“æœå¯¹æ¯”:")
    print("=" * 40)
    
    # è¯»å–ä¹‹å‰çš„ç»“æœ
    prev_file = "data/output/50286_pro_extracted_info.json"
    if os.path.exists(prev_file):
        with open(prev_file, 'r', encoding='utf-8') as f:
            prev_data = json.load(f)
        
        prev_info = prev_data.get('extracted_info', {})
        
        print("ä¹‹å‰çš„é—®é¢˜å­—æ®µ:")
        problem_fields = {
            'ChineseTitle': prev_info.get('ChineseTitle', ''),
            'ChineseAuthor': prev_info.get('ChineseAuthor', ''),
            'EnglishAuthor': prev_info.get('EnglishAuthor', ''),
            'ChineseUniversity': prev_info.get('ChineseUniversity', '')
        }
        
        for field, value in problem_fields.items():
            print(f"   {field}: {value}")
    
    # è¯»å–æ–°çš„ç»“æœ
    new_file = "data/output/50286_cover_extracted_info.json"
    if os.path.exists(new_file):
        with open(new_file, 'r', encoding='utf-8') as f:
            new_data = json.load(f)
        
        new_info = new_data.get('cover_metadata', {})
        
        print("\næ”¹è¿›åçš„ç»“æœ:")
        for field in ['ChineseTitle', 'ChineseAuthor', 'EnglishAuthor', 'ChineseUniversity']:
            value = new_info.get(field, '')
            print(f"   {field}: {value}")


if __name__ == "__main__":
    test_cover_extraction()
    compare_with_previous()

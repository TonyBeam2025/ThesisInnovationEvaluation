#!/usr/bin/env python3
"""
åŸºäºå¤§æ¨¡å‹çš„æ™ºèƒ½å‚è€ƒæ–‡çŒ®æå–
è§£å†³PDFè½¬MDæ ¼å¼ä¸è§„èŒƒçš„é—®é¢˜
"""
import pytest
pytest.skip("integration tests require manual setup (API keys, large data)", allow_module_level=True)
from tests.integration import PROJECT_ROOT

import sys
import os
sys.path.append('src')

from pathlib import Path
import re
import json

def test_smart_ai_references():
    """æ™ºèƒ½AIå‚è€ƒæ–‡çŒ®æå–æµ‹è¯•"""
    # è¯»å–ç¼“å­˜çš„æ–‡æ¡£
    cache_file = Path("cache/documents/åŸºäºç¥ç»ç½‘ç»œçš„ç›¸å¹²å…‰é€šä¿¡ç³»ç»Ÿéçº¿æ€§æŸä¼¤å‡è¡¡æŠ€æœ¯ç ”ç©¶_å†¯æ™“å€©_f28c5133e8a3bd43f6c85222b885a8ce.md")
    
    if not cache_file.exists():
        print(f"âŒ ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨: {cache_file}")
        return
    
    with open(cache_file, 'r', encoding='utf-8') as f:
        text = f.read()
    
    print(f"ğŸ“„ æ–‡æ¡£é•¿åº¦: {len(text):,} å­—ç¬¦")
    
    # å®šä½å‚è€ƒæ–‡çŒ®éƒ¨åˆ†
    print("ğŸ” å®šä½å‚è€ƒæ–‡çŒ®åŒºåŸŸ...")
    ref_section = locate_references_section(text)
    
    if not ref_section:
        print("âŒ æœªæ‰¾åˆ°å‚è€ƒæ–‡çŒ®åŒºåŸŸ")
        return
    
    print(f"ğŸ“ å‚è€ƒæ–‡çŒ®åŒºåŸŸé•¿åº¦: {len(ref_section):,} å­—ç¬¦")
    
    # ä½¿ç”¨æ™ºèƒ½AIæå–
    extract_with_smart_ai(ref_section)

def locate_references_section(text):
    """æ™ºèƒ½å®šä½å‚è€ƒæ–‡çŒ®åŒºåŸŸ"""
    # å¤šç§æ¨¡å¼æŸ¥æ‰¾å‚è€ƒæ–‡çŒ®æ ‡é¢˜
    patterns = [
        r'#+\s*å‚è€ƒæ–‡çŒ®\s*\n',
        r'å‚è€ƒæ–‡çŒ®\s*\n',
        r'References\s*\n',
        r'REFERENCES\s*\n',
        r'Bibliography\s*\n'
    ]
    
    ref_start = -1
    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            ref_start = match.start()
            print(f" æ‰¾åˆ°å‚è€ƒæ–‡çŒ®æ ‡é¢˜: {match.group().strip()}")
            break
    
    if ref_start == -1:
        print("âš ï¸ æœªæ‰¾åˆ°æ ‡å‡†å‚è€ƒæ–‡çŒ®æ ‡é¢˜ï¼Œå°è¯•æ™ºèƒ½æœç´¢...")
        # æœç´¢ç¬¬ä¸€ä¸ªå‚è€ƒæ–‡çŒ®æ¡ç›®
        first_ref_patterns = [
            r'ï¼»1ï¼½',
            r'\[1\]',
            r'^\s*1\.',
            r'^\s*\(1\)'
        ]
        
        for pattern in first_ref_patterns:
            match = re.search(pattern, text, re.MULTILINE)
            if match:
                # å‘å‰æœç´¢å¯èƒ½çš„æ ‡é¢˜
                before_text = text[max(0, match.start()-200):match.start()]
                if 'å‚è€ƒæ–‡çŒ®' in before_text or 'References' in before_text:
                    ref_start = max(0, match.start()-200)
                    print(f" é€šè¿‡ç¬¬ä¸€ä¸ªå‚è€ƒæ–‡çŒ®åæ¨æ‰¾åˆ°åŒºåŸŸ")
                    break
                else:
                    ref_start = match.start()
                    print(f" ç›´æ¥ä»ç¬¬ä¸€ä¸ªå‚è€ƒæ–‡çŒ®å¼€å§‹")
                    break
    
    if ref_start == -1:
        return None
    
    # è¿”å›ä»å‚è€ƒæ–‡çŒ®å¼€å§‹åˆ°æ–‡æ¡£ç»“å°¾çš„éƒ¨åˆ†
    return text[ref_start:]

def extract_with_smart_ai(ref_text):
    """ä½¿ç”¨æ™ºèƒ½AIæå–å‚è€ƒæ–‡çŒ®"""
    try:
        from thesis_inno_eval.ai_client import get_ai_client
        
        print("ğŸ¤– åˆå§‹åŒ–AIå®¢æˆ·ç«¯...")
        ai_client = get_ai_client()
        
        # åˆ†æ®µå¤„ç†é•¿æ–‡æœ¬
        chunks = split_text_intelligently(ref_text)
        print(f"ğŸ“ åˆ†ä¸º {len(chunks)} ä¸ªæ®µè½å¤„ç†")
        
        all_references = []
        
        for i, chunk in enumerate(chunks):
            print(f"ğŸ”„ å¤„ç†ç¬¬ {i+1}/{len(chunks)} æ®µ...")
            
            # æ„å»ºæ™ºèƒ½æç¤ºè¯
            prompt = build_smart_extraction_prompt(chunk, i+1, len(chunks))
            
            # å‘é€è¯·æ±‚
            response = ai_client.send_message(prompt)
            
            if response and hasattr(response, 'content'):
                # è§£æJSONå“åº”
                refs = parse_ai_response(response.content)
                if refs:
                    all_references.extend(refs)
                    print(f"    æå–åˆ° {len(refs)} æ¡å‚è€ƒæ–‡çŒ®")
                else:
                    print(f"   âš ï¸ æœ¬æ®µæœªæå–åˆ°å‚è€ƒæ–‡çŒ®")
            else:
                print(f"   âŒ AIå“åº”ä¸ºç©º")
        
        # å»é‡å’Œæ’åº
        final_refs = deduplicate_and_sort(all_references)
        
        print(f"\nğŸ“Š æœ€ç»ˆæå–ç»“æœ:")
        print(f"   å‚è€ƒæ–‡çŒ®æ€»æ•°: {len(final_refs)} æ¡")
        
        if final_refs:
            print(f"\nğŸ“‹ å‰10æ¡å‚è€ƒæ–‡çŒ®:")
            for i, ref in enumerate(final_refs[:10]):
                print(f"   [{ref['number']}] {ref['content'][:100]}...")
            
            print(f"\nğŸ“‹ æœ€å5æ¡å‚è€ƒæ–‡çŒ®:")
            for ref in final_refs[-5:]:
                print(f"   [{ref['number']}] {ref['content'][:100]}...")
                
            # æ£€æŸ¥ç¼–å·å®Œæ•´æ€§
            check_completeness(final_refs)
        else:
            print("   âŒ æ²¡æœ‰æå–åˆ°æœ‰æ•ˆçš„å‚è€ƒæ–‡çŒ®")
            
    except Exception as e:
        print(f"âŒ AIæå–å¤±è´¥: {e}")

def split_text_intelligently(text, max_chars=8000):
    """æ™ºèƒ½åˆ†å‰²æ–‡æœ¬"""
    if len(text) <= max_chars:
        return [text]
    
    chunks = []
    current_pos = 0
    
    while current_pos < len(text):
        end_pos = min(current_pos + max_chars, len(text))
        
        # åœ¨æ®µè½è¾¹ç•Œåˆ†å‰²
        if end_pos < len(text):
            # å‘åæŸ¥æ‰¾åˆé€‚çš„åˆ†å‰²ç‚¹
            for i in range(end_pos, min(end_pos + 500, len(text))):
                if text[i:i+2] == '\n\n' or (text[i] == '\n' and re.match(r'ï¼»\d+ï¼½', text[i+1:i+10])):
                    end_pos = i
                    break
        
        chunk = text[current_pos:end_pos]
        if chunk.strip():
            chunks.append(chunk)
        
        current_pos = end_pos
    
    return chunks

def build_smart_extraction_prompt(text, chunk_num, total_chunks):
    """æ„å»ºæ™ºèƒ½æå–æç¤ºè¯"""
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦æœ¯æ–‡çŒ®å¤„ç†ä¸“å®¶ã€‚è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–æ‰€æœ‰å‚è€ƒæ–‡çŒ®æ¡ç›®ã€‚

**é‡è¦è¯´æ˜ï¼š**
1. è¿™æ˜¯ç¬¬ {chunk_num}/{total_chunks} æ®µæ–‡æœ¬
2. æ–‡æœ¬å¯èƒ½åŒ…å«PDFè½¬æ¢é”™è¯¯ã€æ ¼å¼ä¸è§„èŒƒç­‰é—®é¢˜
3. å‚è€ƒæ–‡çŒ®ç¼–å·å¯èƒ½ä½¿ç”¨å…¨è§’å­—ç¬¦ï¼šï¼»1ï¼½ã€ï¼»2ï¼½ç­‰
4. å‚è€ƒæ–‡çŒ®å¯èƒ½è·¨è¡Œæ˜¾ç¤ºæˆ–æ ¼å¼æ··ä¹±
5. éœ€è¦æ™ºèƒ½è¯†åˆ«å’Œé‡æ„å®Œæ•´çš„å‚è€ƒæ–‡çŒ®æ¡ç›®

**æå–è¦æ±‚ï¼š**
1. è¯†åˆ«æ‰€æœ‰å‚è€ƒæ–‡çŒ®æ¡ç›®ï¼ŒåŒ…æ‹¬æ ¼å¼ä¸è§„èŒƒçš„
2. é‡æ„æ¯ä¸ªæ¡ç›®ä¸ºå®Œæ•´ã€è§„èŒƒçš„æ ¼å¼
3. ä¿æŒåŸæœ‰ç¼–å·ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
4. æå–å®Œæ•´ä¿¡æ¯ï¼šä½œè€…ã€æ ‡é¢˜ã€æœŸåˆŠ/ä¼šè®®ã€å¹´ä»½ã€é¡µç ç­‰
5. æ¸…ç†å¤šä½™ç©ºç™½ã€æ¢è¡Œå’Œæ ¼å¼é”™è¯¯

**è¾“å‡ºæ ¼å¼ï¼š**
è¯·ä»¥JSONæ•°ç»„æ ¼å¼è¾“å‡ºï¼Œæ¯ä¸ªå‚è€ƒæ–‡çŒ®ä¸ºä¸€ä¸ªå¯¹è±¡ï¼š
```json
[
  {{
    "number": "1",
    "content": "ä½œè€…å. æ–‡ç« æ ‡é¢˜[J]. æœŸåˆŠå, å¹´ä»½, å·(æœŸ): é¡µç .",
    "type": "journal|conference|book|other",
    "confidence": 0.95
  }}
]
```

**æ–‡æœ¬å†…å®¹ï¼š**
{text}

è¯·å¼€å§‹æå–ï¼š"""
    
    return prompt

def parse_ai_response(content):
    """è§£æAIå“åº”"""
    try:
        # å°è¯•ç›´æ¥è§£æJSON
        if content.strip().startswith('['):
            return json.loads(content)
        
        # æŸ¥æ‰¾JSONå—
        json_match = re.search(r'```json\s*(\[.*?\])\s*```', content, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(1))
        
        # æŸ¥æ‰¾ç®€å•çš„JSONæ•°ç»„
        json_match = re.search(r'(\[.*?\])', content, re.DOTALL)
        if json_match:
            return json.loads(json_match.group(1))
        
        # å¦‚æœæ²¡æœ‰JSONæ ¼å¼ï¼Œå°è¯•è§£ææ–‡æœ¬æ ¼å¼
        return parse_text_response(content)
        
    except json.JSONDecodeError as e:
        print(f"   âš ï¸ JSONè§£æå¤±è´¥: {e}")
        return parse_text_response(content)

def parse_text_response(content):
    """è§£ææ–‡æœ¬æ ¼å¼çš„å“åº”"""
    references = []
    lines = content.split('\n')
    
    current_ref = ""
    ref_number = None
    
    for line in lines:
        line = line.strip()
        if not line:
            if current_ref and ref_number:
                references.append({
                    "number": ref_number,
                    "content": current_ref.strip(),
                    "type": "unknown",
                    "confidence": 0.8
                })
                current_ref = ""
                ref_number = None
            continue
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ–°çš„å‚è€ƒæ–‡çŒ®å¼€å§‹
        number_match = re.match(r'^\s*(?:ï¼»(\d+)ï¼½|\[(\d+)\]|(\d+)\.)', line)
        if number_match:
            # ä¿å­˜ä¹‹å‰çš„å‚è€ƒæ–‡çŒ®
            if current_ref and ref_number:
                references.append({
                    "number": ref_number,
                    "content": current_ref.strip(),
                    "type": "unknown", 
                    "confidence": 0.8
                })
            
            # å¼€å§‹æ–°çš„å‚è€ƒæ–‡çŒ®
            ref_number = number_match.group(1) or number_match.group(2) or number_match.group(3)
            current_ref = line
        else:
            # ç»§ç»­å½“å‰å‚è€ƒæ–‡çŒ®
            if current_ref:
                current_ref += " " + line
    
    # ä¿å­˜æœ€åä¸€ä¸ªå‚è€ƒæ–‡çŒ®
    if current_ref and ref_number:
        references.append({
            "number": ref_number,
            "content": current_ref.strip(),
            "type": "unknown",
            "confidence": 0.8
        })
    
    return references

def deduplicate_and_sort(references):
    """å»é‡å’Œæ’åº"""
    # æŒ‰ç¼–å·å»é‡
    seen_numbers = set()
    unique_refs = []
    
    for ref in references:
        if ref['number'] not in seen_numbers:
            seen_numbers.add(ref['number'])
            unique_refs.append(ref)
    
    # æŒ‰ç¼–å·æ’åº
    try:
        unique_refs.sort(key=lambda x: int(x['number']))
    except ValueError:
        # å¦‚æœç¼–å·ä¸æ˜¯çº¯æ•°å­—ï¼ŒæŒ‰å­—ç¬¦ä¸²æ’åº
        unique_refs.sort(key=lambda x: x['number'])
    
    return unique_refs

def check_completeness(references):
    """æ£€æŸ¥ç¼–å·å®Œæ•´æ€§"""
    numbers = [int(ref['number']) for ref in references if ref['number'].isdigit()]
    
    if not numbers:
        print("   âš ï¸ æ— æ³•æ£€æŸ¥ç¼–å·å®Œæ•´æ€§ï¼ˆç¼–å·éæ•°å­—ï¼‰")
        return
    
    min_num = min(numbers)
    max_num = max(numbers)
    expected = set(range(min_num, max_num + 1))
    actual = set(numbers)
    
    missing = expected - actual
    if missing:
        print(f"   âš ï¸ ç¼ºå¤±ç¼–å·: {sorted(missing)}")
    else:
        print(f"    ç¼–å·å®Œæ•´: {min_num}-{max_num}")
    
    duplicates = len(numbers) - len(actual)
    if duplicates > 0:
        print(f"   âš ï¸ é‡å¤ç¼–å·: {duplicates} ä¸ª")

if __name__ == '__main__':
    test_smart_ai_references()

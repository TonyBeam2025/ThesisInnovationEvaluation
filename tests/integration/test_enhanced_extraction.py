#!/usr/bin/env python3
"""
æµ‹è¯•å¢å¼ºç‰ˆå­—æ®µè¡¥å……åŠŸèƒ½
"""
import pytest
pytest.skip("integration tests require manual setup (API keys, large data)", allow_module_level=True)
from tests.integration import PROJECT_ROOT

import os
import sys
import json
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = PROJECT_ROOT
sys.path.insert(0, str(project_root))

def test_enhanced_extraction():
    """æµ‹è¯•å¢å¼ºç‰ˆå­—æ®µè¡¥å……åŠŸèƒ½"""
    
    print("ğŸ¯ æµ‹è¯•å¢å¼ºç‰ˆå­—æ®µè¡¥å……åŠŸèƒ½")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„AIå®¢æˆ·ç«¯
    try:
        from src.thesis_inno_eval.gemini_client import get_ai_client
        ai_client = get_ai_client()
        
        if not ai_client:
            print("âŒ æ— æ³•è·å–AIå®¢æˆ·ç«¯")
            return
            
        print(f" AIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ: {ai_client.get_api_type()}")
        
    except Exception as e:
        print(f"âŒ AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # è¯»å–åŸå§‹Markdownæ–‡ä»¶
    md_file = project_root / "data" / "output" / "Bi-Sb-SeåŸºææ–™çš„åˆ¶å¤‡åŠçƒ­ç”µæ€§èƒ½ç ”ç©¶.md"
    
    if not md_file.exists():
        print(f"âŒ Markdownæ–‡ä»¶ä¸å­˜åœ¨: {md_file}")
        return
    
    print(f"ğŸ“– è¯»å–æ–‡æ¡£: {md_file.name}")
    
    try:
        with open(md_file, 'r', encoding='utf-8') as f:
            text_content = f.read()
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    print(f"ğŸ“Š æ–‡æ¡£é•¿åº¦: {len(text_content):,} å­—ç¬¦")
    
    # è°ƒç”¨å¢å¼ºç‰ˆæå–å‡½æ•°
    try:
        from src.thesis_inno_eval.extract_sections_with_ai import _extract_enhanced_metadata
        
        print("ğŸ” å¼€å§‹å¢å¼ºç‰ˆå…ƒæ•°æ®æå–...")
        result = _extract_enhanced_metadata(text_content, ai_client, "test_enhanced")
        
        if result:
            print(" å¢å¼ºç‰ˆæå–æˆåŠŸï¼")
            
            # æ˜¾ç¤ºç»“æœ
            total_fields = len(result)
            non_empty_fields = len([k for k, v in result.items() if v and str(v).strip()])
            
            print(f"\nğŸ“Š å¢å¼ºç‰ˆæå–ç»“æœ:")
            print(f"   - æ€»å­—æ®µæ•°: {total_fields}")
            print(f"   - éç©ºå­—æ®µæ•°: {non_empty_fields}")
            print(f"   - å®Œæ•´åº¦: {non_empty_fields/total_fields*100:.1f}%")
            
            # æ£€æŸ¥å…³é”®å­—æ®µ
            critical_fields = ['ChineseAuthor', 'ChineseUniversity', 'DegreeLevel', 'ReferenceList', 'ResearchConclusions']
            
            print(f"\nğŸ” å…³é”®å­—æ®µæ£€æŸ¥:")
            for field in critical_fields:
                value = result.get(field, '')
                if value:
                    if isinstance(value, list):
                        print(f"    {field}: {len(value)} é¡¹")
                        if field == 'ReferenceList' and len(value) > 0:
                            print(f"      ç¤ºä¾‹: {value[0][:50]}...")
                    else:
                        preview = str(value)[:100] + "..." if len(str(value)) > 100 else str(value)
                        print(f"    {field}: {preview}")
                else:
                    print(f"   âŒ {field}: [ç©º]")
            
            # ä¿å­˜å¢å¼ºç‰ˆç»“æœ
            output_file = project_root / "data" / "output" / "Bi-Sb-SeåŸºææ–™çš„åˆ¶å¤‡åŠçƒ­ç”µæ€§èƒ½ç ”ç©¶_enhanced_extraction.json"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ’¾ å¢å¼ºç‰ˆç»“æœå·²ä¿å­˜åˆ°: {output_file.name}")
            
            # ä¸ç°æœ‰ç»“æœå¯¹æ¯”
            existing_file = project_root / "data" / "output" / "Bi-Sb-SeåŸºææ–™çš„åˆ¶å¤‡åŠçƒ­ç”µæ€§èƒ½ç ”ç©¶_extracted_info.json"
            
            if existing_file.exists():
                with open(existing_file, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
                
                print(f"\nğŸ“Š ä¸ç°æœ‰ç»“æœå¯¹æ¯”:")
                
                existing_non_empty = len([k for k, v in existing_data.items() if v and str(v).strip()])
                enhanced_non_empty = len([k for k, v in result.items() if v and str(v).strip()])
                
                print(f"   - ç°æœ‰éç©ºå­—æ®µ: {existing_non_empty}")
                print(f"   - å¢å¼ºåéç©ºå­—æ®µ: {enhanced_non_empty}")
                print(f"   - æ”¹è¿›ç¨‹åº¦: +{enhanced_non_empty - existing_non_empty}")
                
                # æ˜¾ç¤ºæ–°è¡¥å……çš„å­—æ®µ
                new_fields = []
                for field in critical_fields:
                    if not existing_data.get(field) and result.get(field):
                        new_fields.append(field)
                
                if new_fields:
                    print(f"   - æ–°è¡¥å……å­—æ®µ: {', '.join(new_fields)}")
                else:
                    print(f"   - æš‚æ— æ–°è¡¥å……å­—æ®µ")
        
        else:
            print("âŒ å¢å¼ºç‰ˆæå–å¤±è´¥")
            
    except Exception as e:
        print(f"âŒ å¢å¼ºç‰ˆæå–å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_enhanced_extraction()

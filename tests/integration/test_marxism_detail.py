"""
ä¸“é—¨æµ‹è¯•é©¬å…‹æ€ä¸»ä¹‰å“²å­¦è®ºæ–‡çš„ç›®å½•æå–
æ£€æŸ¥æ˜¯å¦æ­£ç¡®æå–äº†æ‰€æœ‰å‚è€ƒæ–‡çŒ®åç« èŠ‚
"""
import pytest
pytest.skip("integration tests require manual setup (API keys, large data)", allow_module_level=True)
from tests.integration import PROJECT_ROOT
import sys
import os
sys.path.append(os.path.join(str(PROJECT_ROOT), 'src'))

from thesis_inno_eval.ai_toc_extractor import AITocExtractor
import json

def test_marxism_thesis():
    """æµ‹è¯•é©¬å…‹æ€ä¸»ä¹‰å“²å­¦è®ºæ–‡çš„è¯¦ç»†ç›®å½•æå–"""
    doc_path = r"c:\MyProjects\thesis_Inno_Eval\data\input\1_é©¬å…‹æ€ä¸»ä¹‰å“²å­¦86406_010101_81890101_LW.docx"
    
    print("ğŸ§  æµ‹è¯•é©¬å…‹æ€ä¸»ä¹‰å“²å­¦å­¦ä½è®ºæ–‡è¯¦ç»†ç›®å½•æå–")
    print(f"ğŸ“ æ–‡ä»¶: {os.path.basename(doc_path)}")
    print("="*80)
    
    if not os.path.exists(doc_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {doc_path}")
        return
    
    try:
        # åˆå§‹åŒ–æå–å™¨
        extractor = AITocExtractor()
        
        # æå–ç›®å½•
        print("ğŸ”„ å¼€å§‹æå–ç›®å½•...")
        result = extractor.extract_toc(doc_path)
        
        if result and result.entries:
            print(f"\nğŸ“Š æ€»æå–æ¡ç›®: {len(result.entries)}ä¸ª")
            print(f"ğŸ¯ æ•´ä½“ç½®ä¿¡åº¦: {result.confidence_score:.2f}")
            
            # æ˜¾ç¤ºæ‰€æœ‰æ¡ç›®çš„è¯¦ç»†ä¿¡æ¯
            print(f"\nğŸ“‹ å®Œæ•´ç›®å½•æ¡ç›®åˆ—è¡¨:")
            print("-" * 80)
            
            for i, entry in enumerate(result.entries, 1):
                print(f"{i:2d}. ã€{entry.section_type}ã€‘ {entry.number} {entry.title}")
                print(f"     é¡µç : {entry.page} | çº§åˆ«: {entry.level} | ç½®ä¿¡åº¦: {entry.confidence:.2f}")
            
            # ä¸“é—¨æ£€æŸ¥å‚è€ƒæ–‡çŒ®åç« èŠ‚
            print(f"\nğŸ” å‚è€ƒæ–‡çŒ®åç« èŠ‚æ£€æŸ¥:")
            print("-" * 50)
            
            post_ref_sections = []
            references_found = False
            
            for entry in result.entries:
                if entry.section_type == 'references':
                    references_found = True
                    print(f" æ‰¾åˆ°å‚è€ƒæ–‡çŒ®: {entry.title} (é¡µç : {entry.page})")
                elif entry.section_type in ['achievements', 'acknowledgment', 'author_profile', 'epilogue']:
                    post_ref_sections.append(entry)
            
            if references_found:
                print(f"\nğŸ“– å‚è€ƒæ–‡çŒ®åç« èŠ‚ ({len(post_ref_sections)}ä¸ª):")
                for i, section in enumerate(post_ref_sections, 1):
                    print(f"   {i}. {section.title} (é¡µç : {section.page}, ç±»å‹: {section.section_type})")
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›®æ ‡ç« èŠ‚
            target_sections = [
                "ä¸ªäººç®€å†å’Œæ”»è¯»ç¡•å£«å­¦ä½æœŸé—´çš„ä¸»è¦å­¦æœ¯æˆæœ",
                "åè®°", "åã€€è®°"
            ]
            
            print(f"\nğŸ¯ ç›®æ ‡ç« èŠ‚æ£€æŸ¥:")
            print("-" * 50)
            
            found_targets = []
            for target in target_sections:
                for entry in result.entries:
                    # æ›´çµæ´»çš„åŒ¹é…é€»è¾‘ - ç§»é™¤ç©ºæ ¼å¹¶æ¯”è¾ƒ
                    clean_title = entry.title.replace(" ", "").replace("ã€€", "")
                    clean_target = target.replace(" ", "").replace("ã€€", "")
                    
                    if (target in entry.title or entry.title in target or 
                        clean_target in clean_title or 
                        (target == "åè®°" and "åè®°" in clean_title) or
                        (target == "åã€€è®°" and "åè®°" in clean_title)):
                        found_targets.append((target, entry))
                        print(f" æ‰¾åˆ°: {entry.title} (é¡µç : {entry.page})")
                        break
                else:
                    print(f"âŒ ç¼ºå¤±: {target}")
            
            if len(found_targets) < 2:
                print(f"\nâš ï¸  å¯èƒ½éœ€è¦è°ƒæ•´è¯†åˆ«æ¨¡å¼ä»¥æ•è·æ›´å¤šå‚è€ƒæ–‡çŒ®åç« èŠ‚")
                
        else:
            print("âŒ æå–å¤±è´¥æˆ–ç»“æœä¸ºç©º")
            
    except Exception as e:
        print(f"âŒ æå–è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()

def check_raw_content():
    """æ£€æŸ¥åŸå§‹æ–‡æ¡£å†…å®¹ä»¥ç¡®è®¤ç›®æ ‡ç« èŠ‚å­˜åœ¨"""
    print(f"\nğŸ” æ£€æŸ¥åŸå§‹æ–‡æ¡£å†…å®¹...")
    doc_path = r"c:\MyProjects\thesis_Inno_Eval\data\input\1_é©¬å…‹æ€ä¸»ä¹‰å“²å­¦86406_010101_81890101_LW.docx"
    
    try:
        import docx
        doc = docx.Document(doc_path)
        
        print("ğŸ“„ æœç´¢ç›®æ ‡ç« èŠ‚...")
        targets = ["ä¸ªäººç®€å†", "æ”»è¯»ç¡•å£«å­¦ä½", "åè®°", "åã€€è®°"]
        
        for i, paragraph in enumerate(doc.paragraphs):
            text = paragraph.text.strip()
            if text and any(target in text for target in targets):
                print(f"ç¬¬{i+1}è¡Œ: {text}")
                
    except Exception as e:
        print(f"âŒ æ£€æŸ¥åŸå§‹å†…å®¹å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    test_marxism_thesis()
    check_raw_content()

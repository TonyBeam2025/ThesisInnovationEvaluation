"""
æµ‹è¯•æ™ºèƒ½å‚è€ƒæ–‡çŒ®æå–é›†æˆ
éªŒè¯PDFå’ŒWordæ–‡æ¡£çš„ä¸åŒå¤„ç†ç­–ç•¥
"""
import pytest
pytest.skip("integration tests require manual setup (API keys, large data)", allow_module_level=True)
from tests.integration import PROJECT_ROOT

import os
import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(0, str(PROJECT_ROOT / 'src'))

def test_smart_integration():
    """æµ‹è¯•æ™ºèƒ½å‚è€ƒæ–‡çŒ®æå–é›†æˆ"""
    print("ğŸ§ª æµ‹è¯•æ™ºèƒ½å‚è€ƒæ–‡çŒ®æå–é›†æˆ\n")
    
    try:
        # å¯¼å…¥æ¨¡å—
        from src.thesis_inno_eval.extract_sections_with_ai import ThesisExtractorPro
        print(" æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # åˆå§‹åŒ–æå–å™¨
        print("\nğŸ”§ åˆå§‹åŒ–æ™ºèƒ½æå–å™¨...")
        extractor = ThesisExtractorPro()
        
        # æ£€æŸ¥æ™ºèƒ½æå–å™¨çŠ¶æ€
        if extractor.smart_ref_extractor:
            print(" æ™ºèƒ½å‚è€ƒæ–‡çŒ®æå–å™¨: å¯ç”¨")
        else:
            print("âš ï¸ æ™ºèƒ½å‚è€ƒæ–‡çŒ®æå–å™¨: ä¸å¯ç”¨")
        
        if extractor.ai_client:
            print(" AIå®¢æˆ·ç«¯: å¯ç”¨")
        else:
            print("âš ï¸ AIå®¢æˆ·ç«¯: ä¸å¯ç”¨")
        
        # è¯»å–æµ‹è¯•æ–‡æ¡£
        test_file = "data/input/51177.docx"
        if not os.path.exists(test_file):
            print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
            return
        
        print(f"\nğŸ“„ ä½¿ç”¨Wordæ–‡æ¡£è¿›è¡Œæµ‹è¯•: {test_file}")
        
        # ç”±äºè¿™æ˜¯Wordæ–‡æ¡£ï¼Œæˆ‘ä»¬éœ€è¦å…ˆæå–æ–‡æœ¬
        # ä½†ä¸ºäº†ç®€åŒ–æµ‹è¯•ï¼Œæˆ‘ä»¬ä½¿ç”¨å·²æœ‰çš„markdownç‰ˆæœ¬ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        markdown_file = "data/output/51177_extracted.md"
        if os.path.exists(markdown_file):
            print(f"ğŸ“„ ä½¿ç”¨å·²æå–çš„markdownç‰ˆæœ¬: {markdown_file}")
            with open(markdown_file, 'r', encoding='utf-8') as f:
                text = f.read()
        else:
            print("âš ï¸ æœªæ‰¾åˆ°å·²æå–çš„markdownç‰ˆæœ¬ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ–‡æœ¬è¿›è¡Œæµ‹è¯•")
            # ä½¿ç”¨åŒ…å«å‚è€ƒæ–‡çŒ®çš„æ¨¡æ‹Ÿæ–‡æœ¬
            text = """
# æµ‹è¯•è®ºæ–‡

## æ‘˜è¦
è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æ¡£ç”¨äºéªŒè¯æ™ºèƒ½å‚è€ƒæ–‡çŒ®æå–åŠŸèƒ½ã€‚

## å‚è€ƒæ–‡çŒ®

ï¼»ï¼‘ï¼½ Zhang, J., Smith, A. B., & Johnson, C. D. Machine Learning Approaches in Data Science[J]. Journal of Computer Science, 2023, 45(3): 123-145.

ï¼»ï¼’ï¼½ Li, M., Wang, H., & Chen, Y. Deep Learning for Natural Language Processing[C]//Proceedings of the International Conference on Artificial Intelligence. IEEE, 2023: 456-467.

ï¼»ï¼“ï¼½ ç‹æ˜, æå, å¼ ä¸‰. äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—è¯Šæ–­ä¸­çš„åº”ç”¨ç ”ç©¶[J]. è®¡ç®—æœºå­¦æŠ¥, 2023, 44(2): 234-248.

ï¼»ï¼”ï¼½ Brown, R., Davis, K., & Wilson, L. Advanced Algorithms for Big Data Processing[M]. MIT Press, 2023: 89-112.

ï¼»ï¼•ï¼½ åˆ˜å¼º, é™ˆäº®. åŸºäºæ·±åº¦å­¦ä¹ çš„å›¾åƒè¯†åˆ«æŠ€æœ¯[J]. è½¯ä»¶å­¦æŠ¥, 2023, 34(1): 45-58.
"""
        
        print(f"ğŸ“ æ–‡æ¡£é•¿åº¦: {len(text):,} å­—ç¬¦")
        
        # æµ‹è¯•æ™ºèƒ½å‚è€ƒæ–‡çŒ®æå–
        print("\nğŸ” æµ‹è¯•æ™ºèƒ½å‚è€ƒæ–‡çŒ®æå–...")
        start_time = time.time()
        
        # æ¨¡æ‹ŸPDFæ–‡æ¡£è·¯å¾„
        pdf_test_path = "test_document.pdf"
        references_result = extractor._extract_references_enhanced_disciplinary(
            text, 'engineering', pdf_test_path
        )
        
        processing_time = time.time() - start_time
        
        # æ˜¾ç¤ºç»“æœ
        print(f"\nğŸ“Š æå–ç»“æœ:")
        print(f"   å‚è€ƒæ–‡çŒ®æ•°é‡: {references_result['total_count']} æ¡")
        print(f"   å­¦ç§‘é¢†åŸŸ: {references_result['discipline']}")
        print(f"   å¤„ç†æ—¶é—´: {processing_time:.2f} ç§’")
        
        if 'extraction_stats' in references_result:
            stats = references_result['extraction_stats']
            print(f"   æå–æ–¹æ³•: {stats.get('method_used', 'unknown')}")
            print(f"   æˆåŠŸçŠ¶æ€: {stats.get('success', False)}")
            print(f"   å†…éƒ¨å¤„ç†æ—¶é—´: {stats.get('processing_time', 0):.2f} ç§’")
        
        # æ˜¾ç¤ºå‰å‡ æ¡å‚è€ƒæ–‡çŒ®
        references = references_result['references']
        if references:
            print(f"\nğŸ“‹ å‰5æ¡å‚è€ƒæ–‡çŒ®:")
            for i, ref in enumerate(references[:5], 1):
                print(f"   {i}. {ref[:100]}...")
        
        # æµ‹è¯•Wordæ–‡æ¡£è·¯å¾„
        print(f"\nğŸ” æµ‹è¯•Wordæ–‡æ¡£å¤„ç†...")
        word_test_path = "test_document.docx"
        references_result_word = extractor._extract_references_enhanced_disciplinary(
            text, 'engineering', word_test_path
        )
        
        print(f"   Wordå¤„ç†ç»“æœ: {references_result_word['total_count']} æ¡å‚è€ƒæ–‡çŒ®")
        if 'extraction_stats' in references_result_word:
            stats = references_result_word['extraction_stats']
            print(f"   Wordæå–æ–¹æ³•: {stats.get('method_used', 'unknown')}")
        
        # å¯¹æ¯”åˆ†æ
        print(f"\nğŸ“ˆ å¯¹æ¯”åˆ†æ:")
        print(f"   PDFç­–ç•¥æå–: {references_result['total_count']} æ¡")
        print(f"   Wordç­–ç•¥æå–: {references_result_word['total_count']} æ¡")
        
        if references_result['total_count'] == references_result_word['total_count']:
            print("    ä¸¤ç§ç­–ç•¥ç»“æœä¸€è‡´")
        else:
            print("   âš ï¸ ä¸¤ç§ç­–ç•¥ç»“æœä¸åŒï¼Œç¬¦åˆé¢„æœŸï¼ˆä¸åŒä¼˜åŒ–ç­–ç•¥ï¼‰")
            
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("   è¯·ç¡®ä¿æ‰€æœ‰ä¾èµ–æ¨¡å—éƒ½å·²æ­£ç¡®å®‰è£…")
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def test_format_detection():
    """æµ‹è¯•æ ¼å¼æ£€æµ‹åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•æ ¼å¼æ£€æµ‹åŠŸèƒ½")
    
    try:
        from src.thesis_inno_eval.smart_reference_extractor import SmartReferenceExtractor
        
        # åˆ›å»ºæå–å™¨å®ä¾‹
        extractor = SmartReferenceExtractor()
        
        # æµ‹è¯•ä¸åŒæ–‡ä»¶è·¯å¾„
        test_paths = [
            "document.pdf",
            "document.docx", 
            "document.doc",
            "unknown.txt",
            ""
        ]
        
        for path in test_paths:
            format_detected = extractor._detect_source_format("", path)
            print(f"   {path:15} -> {format_detected}")
            
    except Exception as e:
        print(f"âŒ æ ¼å¼æ£€æµ‹æµ‹è¯•å¤±è´¥: {e}")

if __name__ == "__main__":
    print("=" * 60)
    print("æ™ºèƒ½å‚è€ƒæ–‡çŒ®æå–é›†æˆæµ‹è¯•")
    print("=" * 60)
    
    test_smart_integration()
    test_format_detection()
    
    print("\n æµ‹è¯•å®Œæˆ!")

#!/usr/bin/env python3
"""
å‚è€ƒæ–‡çŒ®ç« èŠ‚è¯†åˆ«å’Œæ ¼å¼å¤„ç†æµ‹è¯•
"""
import pytest
pytest.skip("integration tests require manual setup (API keys, large data)", allow_module_level=True)
from tests.integration import PROJECT_ROOT

import sys
import os
import json
import glob
import re
from typing import Dict, Any, List

# æ·»åŠ æºä»£ç è·¯å¾„
current_dir = str(PROJECT_ROOT)
src_path = os.path.join(current_dir, 'src')
sys.path.insert(0, src_path)

def test_references_recognition():
    """æµ‹è¯•å‚è€ƒæ–‡çŒ®è¯†åˆ«åŠŸèƒ½"""
    
    print("ğŸ“š å‚è€ƒæ–‡çŒ®ç« èŠ‚è¯†åˆ«å’Œæ ¼å¼å¤„ç†æµ‹è¯•")
    print("=" * 80)
    
    # æµ‹è¯•ç”¨çš„å‚è€ƒæ–‡çŒ®æ–‡æœ¬æ ·ä¾‹
    test_cases = [
        {
            'name': 'æ ‡å‡†æ ¼å¼ - æ— ç©ºæ ¼',
            'text': '''
å‚è€ƒæ–‡çŒ®

[1] å¼ ä¸‰, æå››. æœºå™¨å­¦ä¹ ç†è®ºä¸å®è·µ[M]. åŒ—äº¬: æ¸…åå¤§å­¦å‡ºç‰ˆç¤¾, 2020.
[2] Smith J, Brown K. Deep Learning Applications[J]. Nature, 2021, 589: 123-145.
[3] ç‹äº”. ç¥ç»ç½‘ç»œç®—æ³•ä¼˜åŒ–ç ”ç©¶[D]. åŒ—äº¬: åŒ—äº¬å¤§å­¦, 2019.

è‡´è°¢
æ„Ÿè°¢æ‰€æœ‰å¸®åŠ©è¿‡æˆ‘çš„äºº...
'''
        },
        {
            'name': 'å¸¦ç©ºæ ¼æ ¼å¼ - æ ‡é¢˜æœ‰ç©ºæ ¼',
            'text': '''
å‚ è€ƒ æ–‡ çŒ®

[1] å¼ ä¸‰, æå››. æœºå™¨å­¦ä¹ ç†è®ºä¸å®è·µ[M]. åŒ—äº¬: æ¸…åå¤§å­¦å‡ºç‰ˆç¤¾, 2020.

[2] Smith J, Brown K. Deep Learning Applications[J]. Nature, 2021, 589: 123-145.


[3] ç‹äº”. ç¥ç»ç½‘ç»œç®—æ³•ä¼˜åŒ–ç ”ç©¶[D]. åŒ—äº¬: åŒ—äº¬å¤§å­¦, 2019.

è‡´è°¢
'''
        },
        {
            'name': 'æ··åˆæ ¼å¼ - ä¸åŒç¼–å·æ–¹å¼',
            'text': '''
å‚è€ƒæ–‡çŒ®

1. å¼ ä¸‰, æå››. æœºå™¨å­¦ä¹ ç†è®ºä¸å®è·µ[M]. åŒ—äº¬: æ¸…åå¤§å­¦å‡ºç‰ˆç¤¾, 2020.
2. Smith J, Brown K. Deep Learning Applications[J]. Nature, 2021, 589: 123-145.
ã€3ã€‘ç‹äº”. ç¥ç»ç½‘ç»œç®—æ³•ä¼˜åŒ–ç ”ç©¶[D]. åŒ—äº¬: åŒ—äº¬å¤§å­¦, 2019.
(4) èµµå…­. è®¡ç®—æœºè§†è§‰åŸºç¡€[M]. ä¸Šæµ·: å¤æ—¦å¤§å­¦å‡ºç‰ˆç¤¾, 2018.

è‡´è°¢
'''
        },
        {
            'name': 'è‹±æ–‡æ ¼å¼',
            'text': '''
REFERENCES

[1] Zhang S, Li S. Machine Learning Theory and Practice[M]. Beijing: Tsinghua University Press, 2020.
[2] Smith J, Brown K. Deep Learning Applications[J]. Nature, 2021, 589: 123-145.
[3] Wang W. Neural Network Algorithm Optimization Research[D]. Beijing: Peking University, 2019.

ACKNOWLEDGMENT
'''
        },
        {
            'name': 'å¤æ‚æ ¼å¼ - å¤šç§é—®é¢˜',
            'text': '''
å‚   è€ƒ   æ–‡   çŒ®

[1] å¼ ä¸‰, æå››. æœºå™¨å­¦ä¹ ç†è®ºä¸å®è·µ[M]. åŒ—äº¬: æ¸…åå¤§å­¦å‡ºç‰ˆç¤¾, 2020.


[2] Smith J, Brown K. Deep Learning Applications[J]. 
    Nature, 2021, 589: 123-145.



ã€3ã€‘ç‹äº”. ç¥ç»ç½‘ç»œç®—æ³•ä¼˜åŒ–ç ”ç©¶[D]. åŒ—äº¬: åŒ—äº¬å¤§å­¦, 2019.

(4) èµµå…­. è®¡ç®—æœºè§†è§‰åŸºç¡€[M]. 
    ä¸Šæµ·: å¤æ—¦å¤§å­¦å‡ºç‰ˆç¤¾, 2018.

è‡´   è°¢
'''
        }
    ]
    
    # å¯¼å…¥æ”¹è¿›åçš„æå–å™¨
    try:
        import thesis_inno_eval.extract_sections_with_ai as extract_module
        extractor = extract_module.ThesisExtractorPro()
        ai_available = True
    except Exception as e:
        print(f"âš ï¸ AIæå–å™¨ä¸å¯ç”¨: {e}")
        ai_available = False
    
    # æµ‹è¯•æ¯ä¸ªæ ·ä¾‹
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ“– æµ‹è¯•æ¡ˆä¾‹ {i}: {test_case['name']}")
        print(f"{'='*60}")
        
        text = test_case['text']
        print(f"ğŸ“„ åŸå§‹æ–‡æœ¬:")
        print(text)
        
        # ç®€å•æ­£åˆ™æµ‹è¯•
        print(f"\nğŸ” æ­£åˆ™åŒ¹é…æµ‹è¯•:")
        
        # æµ‹è¯•ä¸åŒçš„å‚è€ƒæ–‡çŒ®æ ‡é¢˜æ¨¡å¼
        title_patterns = [
            (r'å‚è€ƒæ–‡çŒ®', 'æ ‡å‡†ä¸­æ–‡'),
            (r'å‚\s*è€ƒ\s*æ–‡\s*çŒ®', 'å¸¦ç©ºæ ¼ä¸­æ–‡'),
            (r'REFERENCES?', 'è‹±æ–‡å¤§å†™'),
            (r'References?', 'è‹±æ–‡é¦–å­—æ¯å¤§å†™'),
        ]
        
        found_titles = []
        for pattern, desc in title_patterns:
            matches = list(re.finditer(pattern, text, re.IGNORECASE))
            if matches:
                for match in matches:
                    line_num = text[:match.start()].count('\n') + 1
                    found_titles.append({
                        'pattern': desc,
                        'text': match.group(0),
                        'line': line_num,
                        'position': match.start()
                    })
        
        if found_titles:
            for title in found_titles:
                print(f"    {title['pattern']}: '{title['text']}' (è¡Œ {title['line']})")
        else:
            print(f"   âŒ æœªæ‰¾åˆ°å‚è€ƒæ–‡çŒ®æ ‡é¢˜")
        
        # æµ‹è¯•æ¡ç›®è¯†åˆ«
        print(f"\nğŸ“ æ¡ç›®è¯†åˆ«æµ‹è¯•:")
        
        # æå–å‚è€ƒæ–‡çŒ®å†…å®¹
        if found_titles:
            start_pos = min(title['position'] for title in found_titles)
            # æŸ¥æ‰¾ç»“æŸä½ç½®
            end_patterns = [r'è‡´\s*è°¢', r'ACKNOWLEDGMENT', r'é™„\s*å½•']
            end_pos = len(text)
            for pattern in end_patterns:
                match = re.search(pattern, text[start_pos:], re.IGNORECASE)
                if match:
                    end_pos = start_pos + match.start()
                    break
            
            ref_content = text[start_pos:end_pos]
            
            # è¯†åˆ«ä¸åŒçš„æ¡ç›®æ ¼å¼
            item_patterns = [
                (r'\[\s*\d+\s*\]', 'æ–¹æ‹¬å·ç¼–å·'),
                (r'\(\s*\d+\s*\)', 'åœ†æ‹¬å·ç¼–å·'),
                (r'ã€\s*\d+\s*ã€‘', 'ä¸­æ–‡æ–¹æ‹¬å·'),
                (r'^\s*\d+\.\s*', 'æ•°å­—ç‚¹å·'),
            ]
            
            total_items = 0
            for pattern, desc in item_patterns:
                items = re.findall(pattern, ref_content, re.MULTILINE)
                if items:
                    print(f"   ğŸ“Œ {desc}: {len(items)} ä¸ª - {', '.join(items[:3])}{'...' if len(items) > 3 else ''}")
                    total_items = max(total_items, len(items))
            
            print(f"   ğŸ“Š ä¼°è®¡æ€»æ¡ç›®æ•°: {total_items}")
            
            # æ£€æµ‹æ ¼å¼é—®é¢˜
            print(f"\nâš ï¸ æ ¼å¼é—®é¢˜æ£€æµ‹:")
            issues = []
            
            # æ£€æŸ¥æ ‡é¢˜ç©ºæ ¼
            for title in found_titles:
                if re.search(r'å‚\s+è€ƒ|è€ƒ\s+æ–‡|æ–‡\s+çŒ®', title['text']):
                    issues.append(f"æ ‡é¢˜å¼‚å¸¸ç©ºæ ¼: '{title['text']}'")
            
            # æ£€æŸ¥æ¡ç›®é—´ç©ºè¡Œ
            lines = ref_content.split('\n')
            empty_line_count = 0
            for i, line in enumerate(lines):
                if line.strip() == '':
                    empty_line_count += 1
                    if i > 0 and i < len(lines) - 1:
                        prev_line = lines[i-1].strip()
                        next_line = lines[i+1].strip()
                        if (re.match(r'[\[\(ã€]?\d+[\]\)ã€‘]?', prev_line) and 
                            re.match(r'[\[\(ã€]?\d+[\]\)ã€‘]?', next_line)):
                            issues.append(f"æ¡ç›®é—´å¤šä½™ç©ºè¡Œ: è¡Œ {i+1}")
            
            if issues:
                for issue in issues:
                    print(f"   ğŸ”´ {issue}")
            else:
                print(f"    æ ¼å¼æ£€æŸ¥é€šè¿‡")
            
            print(f"   ğŸ“Š ç©ºè¡Œç»Ÿè®¡: {empty_line_count} è¡Œ")
        
        # AIæå–å™¨æµ‹è¯•
        if ai_available and 'extractor' in locals():
            print(f"\nğŸ¤– AIæå–å™¨æµ‹è¯•:")
            try:
                sections = extractor._analyze_document_structure(text)
                
                if 'references' in sections:
                    ref_info = sections.get('references_info', {})
                    print(f"    AIè¯†åˆ«æˆåŠŸ")
                    if isinstance(ref_info, dict):
                        print(f"   ğŸ“‹ æ ‡é¢˜: {ref_info.get('title', 'N/A')}")
                        print(f"   ğŸ“ é•¿åº¦: {ref_info.get('content_length', 0)} å­—ç¬¦")
                        print(f"   ğŸ¯ ç½®ä¿¡åº¦: {ref_info.get('boundary_confidence', 0):.2f}")
                    
                    ref_content = sections['references']
                    preview = ref_content[:150].replace('\n', ' ')
                    print(f"   ğŸ“„ å†…å®¹é¢„è§ˆ: {preview}...")
                else:
                    print(f"   âŒ AIæœªè¯†åˆ«åˆ°å‚è€ƒæ–‡çŒ®")
            except Exception as e:
                print(f"   âš ï¸ AIæµ‹è¯•å¤±è´¥: {e}")
    
    # æµ‹è¯•çœŸå®æ–‡æ¡£
    print(f"\n{'='*80}")
    print(f"ğŸ“š çœŸå®æ–‡æ¡£æµ‹è¯•")
    print(f"{'='*80}")
    
    # è·å–ç¼“å­˜æ–‡æ¡£
    cache_dir = os.path.join(current_dir, 'cache', 'documents')
    if os.path.exists(cache_dir):
        md_files = glob.glob(os.path.join(cache_dir, "*.md"))
        md_files.sort(key=lambda x: os.path.getmtime(x), reverse=True)
        
        for md_file in md_files[:2]:  # æµ‹è¯•æœ€æ–°çš„2ä¸ªæ–‡æ¡£
            filename = os.path.basename(md_file)
            print(f"\nğŸ“– æµ‹è¯•æ–‡æ¡£: {filename}")
            
            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # æŸ¥æ‰¾å‚è€ƒæ–‡çŒ®
                ref_patterns = [
                    r'å‚\s*è€ƒ\s*æ–‡\s*çŒ®',
                    r'REFERENCES?',
                    r'References?'
                ]
                
                found = False
                for pattern in ref_patterns:
                    matches = list(re.finditer(pattern, content, re.IGNORECASE))
                    if matches:
                        found = True
                        for match in matches:
                            line_num = content[:match.start()].count('\n') + 1
                            print(f"    æ‰¾åˆ°: '{match.group(0)}' (è¡Œ {line_num})")
                        break
                
                if not found:
                    print(f"   âŒ æœªæ‰¾åˆ°å‚è€ƒæ–‡çŒ®ç« èŠ‚")
                
                # AIæµ‹è¯•
                if ai_available and 'extractor' in locals():
                    try:
                        sections = extractor._analyze_document_structure(content)
                        if 'references' in sections:
                            ref_info = sections.get('references_info', {})
                            if isinstance(ref_info, dict):
                                print(f"   ğŸ¤– AIè¯†åˆ«: {ref_info.get('title', 'N/A')} (ç½®ä¿¡åº¦: {ref_info.get('boundary_confidence', 0):.2f})")
                    except:
                        pass
                        
            except Exception as e:
                print(f"   âš ï¸ è¯»å–å¤±è´¥: {e}")
    
    print(f"\n å‚è€ƒæ–‡çŒ®æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    test_references_recognition()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
51177è®ºæ–‡ç›®å½•ç« èŠ‚ä¿¡æ¯åˆ†æ
ä½¿ç”¨å¿ƒè„æˆåƒè®ºæ–‡æå–å™¨æ¡†æ¶åˆ†æ51177è®ºæ–‡çš„ç»“æ„
"""

import re
import json
from typing import Dict, List, Tuple

def analyze_51177_thesis_structure():
    """åˆ†æ51177è®ºæ–‡çš„ç›®å½•ç»“æ„"""
    
    # è¯»å–æ–‡æ¡£
    with open(r'c:\MyProjects\thesis_Inno_Eval\cache\documents\51177_b6ac1c475108811bd4a31a6ebcd397df.md', 
              'r', encoding='utf-8') as f:
        content = f.read()
    
    print("=== 51177è®ºæ–‡ç›®å½•ç« èŠ‚ä¿¡æ¯åˆ†æ ===\n")
    
    # åŸºæœ¬ä¿¡æ¯
    print("ğŸ“„ è®ºæ–‡åŸºæœ¬ä¿¡æ¯:")
    title_match = re.search(r'Bi-Sb-SeåŸºææ–™çš„.*?åˆ¶å¤‡åŠçƒ­ç”µæ€§èƒ½ç ”ç©¶', content)
    if title_match:
        print(f"   æ ‡é¢˜: {title_match.group()}")
    
    author_match = re.search(r'ä½œè€…å§“å\s+(\S+)', content)
    if author_match:
        print(f"   ä½œè€…: {author_match.group(1)}")
    
    supervisor_match = re.search(r'æŒ‡å¯¼æ•™å¸ˆ\s+(\S+)', content)
    if supervisor_match:
        print(f"   æŒ‡å¯¼æ•™å¸ˆ: {supervisor_match.group(1)}")
    
    print(f"   æ–‡æ¡£å­—ç¬¦æ•°: {len(content):,}")
    print()
    
    # æå–ç›®å½•ç»“æ„
    print("ğŸ“‹ ç›®å½•ç»“æ„åˆ†æ:")
    
    # æŸ¥æ‰¾ç›®å½•éƒ¨åˆ†
    toc_match = re.search(r'ç›®\s*å½•(.*?)ä¸»è¦ç¬¦å·è¡¨', content, re.DOTALL)
    if not toc_match:
        print("âŒ æœªæ‰¾åˆ°ç›®å½•éƒ¨åˆ†")
        return
    
    toc_content = toc_match.group(1)
    lines = toc_content.split('\n')
    
    # åˆ†æç›®å½•é¡¹
    sections = []
    current_chapter = None
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        # åŒ¹é…ä¸»ç« èŠ‚ (### ç¬¬Xç« )
        main_chapter_match = re.match(r'###\s+(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­1-6]ç« )\s+([^	\d]+)', line)
        if main_chapter_match:
            chapter_num = main_chapter_match.group(1)
            chapter_title = main_chapter_match.group(2).strip()
            current_chapter = {
                'type': 'main_chapter',
                'number': chapter_num,
                'title': chapter_title,
                'subsections': []
            }
            sections.append(current_chapter)
            print(f"   ğŸ“š {chapter_num}: {chapter_title}")
            continue
        
        # åŒ¹é…å­ç« èŠ‚ (### X.Y)
        sub_chapter_match = re.match(r'###\s+(\d+\.\d+(?:\.\d+)?)\s+([^	\d]+)', line)
        if sub_chapter_match:
            section_num = sub_chapter_match.group(1)
            section_title = sub_chapter_match.group(2).strip()
            subsection = {
                'type': 'subsection',
                'number': section_num,
                'title': section_title
            }
            if current_chapter:
                current_chapter['subsections'].append(subsection)
            print(f"      ğŸ”¸ {section_num} {section_title}")
            continue
        
        # åŒ¹é…å…¶ä»–ç‰¹æ®Šç« èŠ‚
        special_match = re.match(r'###?\s*([^#\d][^	]*)', line)
        if special_match:
            special_title = special_match.group(1).strip()
            if special_title and not re.match(r'\d+$', special_title):
                sections.append({
                    'type': 'special_section',
                    'title': special_title
                })
                print(f"   ğŸ“„ ç‰¹æ®Šç« èŠ‚: {special_title}")
    
    print(f"\nğŸ“Š ç»“æ„ç»Ÿè®¡:")
    main_chapters = [s for s in sections if s.get('type') == 'main_chapter']
    special_sections = [s for s in sections if s.get('type') == 'special_section']
    total_subsections = sum(len(ch.get('subsections', [])) for ch in main_chapters)
    
    print(f"   ä¸»ç« èŠ‚æ•°: {len(main_chapters)}")
    print(f"   å­ç« èŠ‚æ•°: {total_subsections}")
    print(f"   ç‰¹æ®Šç« èŠ‚æ•°: {len(special_sections)}")
    print(f"   æ€»ç« èŠ‚æ•°: {len(main_chapters) + total_subsections + len(special_sections)}")
    
    # åˆ†æç« èŠ‚å±‚æ¬¡
    print(f"\nğŸ” ç« èŠ‚å±‚æ¬¡åˆ†æ:")
    for chapter in main_chapters:
        subsection_count = len(chapter.get('subsections', []))
        print(f"   {chapter['number']}: {subsection_count} ä¸ªå­ç« èŠ‚")
        if subsection_count > 0:
            for sub in chapter['subsections'][:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                print(f"     - {sub['number']} {sub['title']}")
            if subsection_count > 3:
                print(f"     - ... è¿˜æœ‰ {subsection_count - 3} ä¸ªå­ç« èŠ‚")
    
    # ç‰¹æ®Šç»“æ„åˆ†æ
    print(f"\nğŸ’¡ ç»“æ„ç‰¹ç‚¹:")
    print("1. é‡‡ç”¨æ ‡å‡†çš„åšå£«è®ºæ–‡ç»“æ„")
    print("2. ä¸»ç« èŠ‚ä½¿ç”¨ '### ç¬¬Xç« ' æ ¼å¼")
    print("3. å­ç« èŠ‚ä½¿ç”¨ '### X.Y' æ•°å­—ç¼–å·æ ¼å¼")
    print("4. åŒ…å«å®Œæ•´çš„å‰ç½®å’Œåç½®éƒ¨åˆ†")
    print("5. ä¸“ä¸šæœ¯è¯­è¾ƒå¤šï¼Œå±äºææ–™ç§‘å­¦é¢†åŸŸ")
    
    # ä¸å¿ƒè„æˆåƒè®ºæ–‡çš„å¯¹æ¯”
    print(f"\nï¿½ ä¸å¿ƒè„æˆåƒè®ºæ–‡ç»“æ„å¯¹æ¯”:")
    print("ç›¸åŒç‚¹:")
    print("- éƒ½ä½¿ç”¨ ### æ ‡è®°å­ç« èŠ‚")
    print("- éƒ½æœ‰æ¸…æ™°çš„æ•°å­—ç¼–å·ç³»ç»Ÿ")
    print("- éƒ½åŒ…å«å¤šå±‚æ¬¡çš„åµŒå¥—ç»“æ„")
    print()
    print("ä¸åŒç‚¹:")
    print("- 51177ä½¿ç”¨ä¼ ç»Ÿçš„'ç¬¬Xç« 'æ ¼å¼ï¼Œå¿ƒè„æˆåƒä½¿ç”¨çº¯æ•°å­—")
    print("- 51177å­ç« èŠ‚ç¼–å·æ›´å¤æ‚ (X.Y.Z)ï¼Œå¿ƒè„æˆåƒç›¸å¯¹ç®€å• (X.Y)")
    print("- 51177å±äºææ–™ç§‘å­¦ï¼Œå¿ƒè„æˆåƒå±äºåŒ»å­¦å·¥ç¨‹")
    
    # ä¿å­˜åˆ†æç»“æœ
    result = {
        'thesis_info': {
            'title': title_match.group() if title_match else '',
            'author': author_match.group(1) if author_match else '',
            'supervisor': supervisor_match.group(1) if supervisor_match else '',
            'char_count': len(content)
        },
        'structure': {
            'main_chapters': len(main_chapters),
            'total_subsections': total_subsections,
            'special_sections': len(special_sections)
        },
        'sections': sections
    }
    
    with open('51177_thesis_structure_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜åˆ°: 51177_thesis_structure_analysis.json")
    
    return result

if __name__ == "__main__":
    analyze_51177_thesis_structure()
    
    try:
        with open(md_file, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    print(f"ğŸ“Š æ–‡ä»¶æ€»é•¿åº¦: {len(content):,} å­—ç¬¦")
    
    # åˆ†å‰²æˆè¡Œè¿›è¡Œåˆ†æ
    lines = content.split('\n')
    print(f"ğŸ“„ æ€»è¡Œæ•°: {len(lines):,} è¡Œ")
    
    # å®šä½å…³é”®éƒ¨åˆ†
    sections = {
        "å°é¢ä¿¡æ¯": [],
        "æ‘˜è¦éƒ¨åˆ†": [],
        "ç›®å½•éƒ¨åˆ†": [],
        "æ­£æ–‡å¼€å§‹": [],
        "å‚è€ƒæ–‡çŒ®": [],
        "ç»“è®ºéƒ¨åˆ†": []
    }
    
    # å…³é”®è¯æ¨¡å¼
    patterns = {
        "å°é¢ä¿¡æ¯": [
            r"å­¦ä½è®ºæ–‡", r"ç¡•å£«è®ºæ–‡", r"åšå£«è®ºæ–‡", r"æ¯•ä¸šè®ºæ–‡",
            r"ç”³è¯·å­¦ä½", r"å­¦ä½çº§åˆ«", r"åŸ¹å…»å•ä½", r"æŒ‡å¯¼æ•™å¸ˆ",
            r"å­¦ç§‘ä¸“ä¸š", r"ç ”ç©¶æ–¹å‘", r"ç­”è¾©æ—¥æœŸ"
        ],
        "æ‘˜è¦éƒ¨åˆ†": [
            r"æ‘˜\s*è¦", r"abstract", r"å…³é”®è¯", r"keywords"
        ],
        "ç›®å½•éƒ¨åˆ†": [
            r"ç›®\s*å½•", r"contents", r"ç¬¬.*ç« ", r"ç¬¬.*èŠ‚",
            r"^\s*\d+\..*", r"^\s*\d+\.\d+.*"
        ],
        "æ­£æ–‡å¼€å§‹": [
            r"å¼•è¨€", r"ç»ªè®º", r"æ¦‚è¿°", r"ç¬¬ä¸€ç« ", r"ç¬¬1ç« ",
            r"1\s*å¼•è¨€", r"1\s*ç»ªè®º"
        ],
        "å‚è€ƒæ–‡çŒ®": [
            r"å‚è€ƒæ–‡çŒ®", r"references", r"å¼•ç”¨æ–‡çŒ®", r"æ–‡çŒ®", r"\[\d+\]"
        ],
        "ç»“è®ºéƒ¨åˆ†": [
            r"ç»“è®º", r"æ€»ç»“", r"conclusion", r"ç»“è¯­", r"å°ç»“"
        ]
    }
    
    # æ‰«ææ–‡ä»¶ï¼ŒæŸ¥æ‰¾å…³é”®éƒ¨åˆ†
    for line_no, line in enumerate(lines, 1):
        line_clean = line.strip().lower()
        line_orig = line.strip()
        
        # è·³è¿‡ç©ºè¡Œ
        if not line_clean:
            continue
        
        # æ£€æŸ¥æ¯ä¸ªç±»åˆ«
        for section_name, section_patterns in patterns.items():
            for pattern in section_patterns:
                if re.search(pattern, line_clean, re.IGNORECASE):
                    sections[section_name].append({
                        'line_no': line_no,
                        'content': line_orig[:100] + "..." if len(line_orig) > 100 else line_orig,
                        'pattern': pattern
                    })
                    break
    
    # è¾“å‡ºç»“æœ
    print("\n" + "="*60)
    print("ğŸ“ å…³é”®éƒ¨åˆ†å®šä½ç»“æœ")
    print("="*60)
    
    for section_name, matches in sections.items():
        print(f"\nğŸ”¸ {section_name}:")
        if matches:
            # æ˜¾ç¤ºå‰5ä¸ªåŒ¹é…
            for i, match in enumerate(matches[:5]):
                print(f"   ç¬¬{match['line_no']:,}è¡Œ: {match['content']}")
                if i == 0:
                    # æ˜¾ç¤ºç¬¬ä¸€ä¸ªåŒ¹é…å‘¨å›´çš„å†…å®¹
                    start_line = max(0, match['line_no'] - 3)
                    end_line = min(len(lines), match['line_no'] + 2)
                    print(f"   ğŸ“– ä¸Šä¸‹æ–‡ (ç¬¬{start_line+1}-{end_line}è¡Œ):")
                    for j in range(start_line, end_line):
                        prefix = "   >>> " if j == match['line_no'] - 1 else "       "
                        context_line = lines[j].strip()[:80]
                        if context_line:
                            print(f"{prefix}{context_line}")
            
            if len(matches) > 5:
                print(f"   ... è¿˜æœ‰ {len(matches) - 5} ä¸ªåŒ¹é…")
        else:
            print("   âŒ æœªæ‰¾åˆ°ç›¸å…³å†…å®¹")
    
    # æå–å…·ä½“ä¿¡æ¯
    print("\n" + "="*60)
    print("ğŸ“‹ æå–çš„å…·ä½“ä¿¡æ¯")
    print("="*60)
    
    # å°è¯•æå–æ ‡é¢˜
    title_candidates = []
    for line_no in range(min(50, len(lines))):  # å‰50è¡Œ
        line = lines[line_no].strip()
        if line and len(line) > 10 and len(line) < 100:
            # å¯èƒ½çš„æ ‡é¢˜ç‰¹å¾
            if any(keyword in line.lower() for keyword in ['ç ”ç©¶', 'åˆ†æ', 'è®¾è®¡', 'ç³»ç»Ÿ', 'æ–¹æ³•', 'æŠ€æœ¯']):
                title_candidates.append({
                    'line_no': line_no + 1,
                    'content': line
                })
    
    print("\nğŸ¯ å¯èƒ½çš„è®ºæ–‡æ ‡é¢˜:")
    for candidate in title_candidates[:3]:
        print(f"   ç¬¬{candidate['line_no']}è¡Œ: {candidate['content']}")
    
    # å°è¯•æå–ä½œè€…ä¿¡æ¯
    author_candidates = []
    for line_no in range(min(100, len(lines))):  # å‰100è¡Œ
        line = lines[line_no].strip()
        if re.search(r'(ä½œè€…|ç”³è¯·äºº|ç ”ç©¶ç”Ÿ|å­¦ç”Ÿ)[:ï¼š]', line):
            author_candidates.append({
                'line_no': line_no + 1,
                'content': line
            })
    
    print("\nğŸ‘¤ å¯èƒ½çš„ä½œè€…ä¿¡æ¯:")
    for candidate in author_candidates[:3]:
        print(f"   ç¬¬{candidate['line_no']}è¡Œ: {candidate['content']}")
    
    # å°è¯•æå–å­¦æ ¡ä¿¡æ¯
    university_candidates = []
    for line_no in range(min(100, len(lines))):  # å‰100è¡Œ
        line = lines[line_no].strip()
        if re.search(r'(å¤§å­¦|å­¦é™¢|å­¦æ ¡|university)', line, re.IGNORECASE):
            university_candidates.append({
                'line_no': line_no + 1,
                'content': line
            })
    
    print("\nğŸ« å¯èƒ½çš„å­¦æ ¡ä¿¡æ¯:")
    for candidate in university_candidates[:3]:
        print(f"   ç¬¬{candidate['line_no']}è¡Œ: {candidate['content']}")
    
    # ç»™å‡ºå»ºè®®çš„æ–‡æœ¬åˆ†å‰²ç­–ç•¥
    print("\n" + "="*60)
    print("ğŸ’¡ å»ºè®®çš„æ–‡æœ¬åˆ†å‰²ç­–ç•¥")
    print("="*60)
    
    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæ­£æ–‡æ ‡å¿—
    content_start = None
    for match in sections["æ­£æ–‡å¼€å§‹"]:
        content_start = match['line_no']
        break
    
    if not content_start:
        # å¦‚æœæ²¡æ‰¾åˆ°æ˜ç¡®çš„æ­£æ–‡å¼€å§‹ï¼Œå°è¯•æ‰¾ç›®å½•åçš„ä½ç½®
        if sections["ç›®å½•éƒ¨åˆ†"]:
            content_start = sections["ç›®å½•éƒ¨åˆ†"][-1]['line_no'] + 20  # ç›®å½•å20è¡Œ
    
    # æ‰¾åˆ°å‚è€ƒæ–‡çŒ®å¼€å§‹
    ref_start = None
    for match in sections["å‚è€ƒæ–‡çŒ®"]:
        ref_start = match['line_no']
        break
    
    print(f"ğŸ“– å»ºè®®åˆ†å‰²æ–¹æ¡ˆ:")
    print(f"   å‰ç½®éƒ¨åˆ† (å°é¢+æ‘˜è¦): ç¬¬1è¡Œ - ç¬¬{content_start or 200}è¡Œ")
    print(f"   æ­£æ–‡éƒ¨åˆ†: ç¬¬{content_start or 200}è¡Œ - ç¬¬{ref_start or len(lines)-100}è¡Œ")
    print(f"   å‚è€ƒæ–‡çŒ®éƒ¨åˆ†: ç¬¬{ref_start or len(lines)-100}è¡Œ - ç¬¬{len(lines)}è¡Œ")
    
    # å­—ç¬¦ç»Ÿè®¡
    if content_start:
        front_matter_chars = len('\n'.join(lines[:content_start]))
        print(f"   å‰ç½®éƒ¨åˆ†å­—ç¬¦æ•°: {front_matter_chars:,}")
    
    if content_start and ref_start:
        main_content_chars = len('\n'.join(lines[content_start:ref_start]))
        print(f"   æ­£æ–‡éƒ¨åˆ†å­—ç¬¦æ•°: {main_content_chars:,}")

if __name__ == "__main__":
    analyze_md_structure()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æWordæ–‡æ¡£çš„å®é™…ç« èŠ‚ç»“æ„
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import docx
import re

def analyze_word_structure():
    """åˆ†æWordæ–‡æ¡£ç»“æ„"""
    print("ğŸ“– åˆ†æWordæ–‡æ¡£ç»“æ„...")
    
    file_path = r".\data\input\è·¨æ¨¡æ€å›¾åƒèåˆæŠ€æœ¯åœ¨åŒ»ç–—å½±åƒåˆ†æä¸­çš„ç ”ç©¶.docx"
    
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return
    
    try:
        # è¯»å–Wordæ–‡æ¡£
        doc = docx.Document(file_path)
        
        print(f"\nğŸ“„ æ–‡æ¡£æ®µè½æ€»æ•°: {len(doc.paragraphs)}")
        
        # åˆ†ææ®µè½æ ·å¼
        styles = {}
        for para in doc.paragraphs:
            style_name = para.style.name if para.style else "Normal"
            if style_name not in styles:
                styles[style_name] = 0
            styles[style_name] += 1
        
        print(f"\nğŸ¨ æ®µè½æ ·å¼åˆ†å¸ƒ:")
        for style, count in sorted(styles.items(), key=lambda x: x[1], reverse=True):
            print(f"   {style}: {count}")
        
        # æŸ¥æ‰¾å¯èƒ½çš„ç« èŠ‚æ ‡é¢˜
        print(f"\nğŸ” æŸ¥æ‰¾å¯èƒ½çš„ç« èŠ‚æ ‡é¢˜...")
        potential_headings = []
        
        for i, para in enumerate(doc.paragraphs):
            text = para.text.strip()
            if text:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡é¢˜æ ·å¼
                style_name = para.style.name if para.style else "Normal"
                
                # æ£€æŸ¥æ˜¯å¦åŒ¹é…ç« èŠ‚æ¨¡å¼
                chapter_patterns = [
                    r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+ç« ',
                    r'^ç¬¬\d+ç« ',
                    r'^Chapter\s+\d+',
                    r'^ç»ªè®º$',
                    r'^å¼•è¨€$',
                    r'^æ–‡çŒ®ç»¼è¿°$',
                    r'^ç›¸å…³å·¥ä½œ$',
                    r'^å›½å†…å¤–ç ”ç©¶ç°çŠ¶$',
                    r'^ç»“\s*è®º$',
                    r'^æ€»\s*ç»“$',
                    r'^å‚è€ƒæ–‡çŒ®$',
                    r'^è‡´\s*è°¢$',
                    r'^è°¢\s*è¾$',
                    r'^é™„\s*å½•$',
                ]
                
                is_chapter = any(re.match(pattern, text, re.IGNORECASE) for pattern in chapter_patterns)
                
                # æ£€æŸ¥å­—ä½“å±æ€§
                is_bold = False
                font_size = None
                try:
                    if para.runs:
                        first_run = para.runs[0]
                        is_bold = first_run.bold if first_run.bold is not None else False
                        font_size = first_run.font.size
                except:
                    pass
                
                if (is_chapter or 
                    (style_name and "Heading" in style_name) or 
                    len(text) < 50 and (is_bold or font_size)):
                    
                    potential_headings.append({
                        'index': i,
                        'text': text,
                        'style': style_name,
                        'is_bold': is_bold,
                        'font_size': font_size,
                        'is_chapter_pattern': is_chapter
                    })
        
        print(f"\nğŸ“‹ æ½œåœ¨ç« èŠ‚æ ‡é¢˜ ({len(potential_headings)} ä¸ª):")
        for heading in potential_headings:
            print(f"   [{heading['index']}] {heading['text']}")
            print(f"       æ ·å¼: {heading['style']}, ç²—ä½“: {heading['is_bold']}, å­—å·: {heading['font_size']}, ç« èŠ‚æ¨¡å¼: {heading['is_chapter_pattern']}")
        
        # æŸ¥æ‰¾å‚è€ƒæ–‡çŒ®éƒ¨åˆ†
        print(f"\nğŸ“š æŸ¥æ‰¾å‚è€ƒæ–‡çŒ®éƒ¨åˆ†...")
        ref_found = False
        for i, para in enumerate(doc.paragraphs):
            text = para.text.strip()
            if re.match(r'^(å‚è€ƒæ–‡çŒ®|REFERENCES?)$', text, re.IGNORECASE):
                print(f"   æ‰¾åˆ°å‚è€ƒæ–‡çŒ®æ ‡é¢˜: [{i}] {text}")
                ref_found = True
                
                # æŸ¥çœ‹åç»­å‡ ä¸ªæ®µè½
                print(f"   åç»­å†…å®¹:")
                for j in range(i+1, min(i+6, len(doc.paragraphs))):
                    next_text = doc.paragraphs[j].text.strip()
                    if next_text:
                        print(f"     [{j}] {next_text[:100]}...")
                break
        
        if not ref_found:
            print("   âŒ æœªæ‰¾åˆ°å‚è€ƒæ–‡çŒ®æ ‡é¢˜")
        
        # æŸ¥æ‰¾è‡´è°¢éƒ¨åˆ†
        print(f"\nğŸ™ æŸ¥æ‰¾è‡´è°¢éƒ¨åˆ†...")
        ack_found = False
        for i, para in enumerate(doc.paragraphs):
            text = para.text.strip()
            if re.match(r'^(è‡´\s*è°¢|è°¢\s*è¾|ACKNOWLEDGEMENTS?)$', text, re.IGNORECASE):
                print(f"   æ‰¾åˆ°è‡´è°¢æ ‡é¢˜: [{i}] {text}")
                ack_found = True
                
                # æŸ¥çœ‹åç»­å‡ ä¸ªæ®µè½
                print(f"   åç»­å†…å®¹:")
                for j in range(i+1, min(i+6, len(doc.paragraphs))):
                    next_text = doc.paragraphs[j].text.strip()
                    if next_text:
                        print(f"     [{j}] {next_text[:100]}...")
                break
        
        if not ack_found:
            print("   âŒ æœªæ‰¾åˆ°è‡´è°¢æ ‡é¢˜")
        
    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    analyze_word_structure()

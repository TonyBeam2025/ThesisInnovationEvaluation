#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å•ä¸ªWordæ–‡æ¡£ç›®å½•æ·±åº¦åˆ†æžæµ‹è¯•
"""

import sys
import os
import json
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from thesis_inno_eval.ai_toc_extractor import AITocExtractor
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def analyze_single_document(file_path: str):
    """æ·±åº¦åˆ†æžå•ä¸ªWordæ–‡æ¡£"""
    
    file_path_obj = Path(file_path)
    if not file_path_obj.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return
    
    print(f"ðŸ” å¼€å§‹åˆ†æžæ–‡æ¡£: {file_path_obj.name}")
    print("=" * 80)
    
    # åˆ›å»ºæŠ½å–å™¨
    extractor = AITocExtractor()
    
    try:
        # æŠ½å–ç›®å½•
        toc = extractor.extract_toc(str(file_path_obj))
        
        # åŸºæœ¬ä¿¡æ¯
        print(f"ðŸ“‹ è®ºæ–‡æ ‡é¢˜: {toc.title or 'æœªè¯†åˆ«'}")
        print(f"ðŸ‘¤ ä½œè€…: {toc.author or 'æœªè¯†åˆ«'}")
        print(f"ðŸ“Š æ€»æ¡ç›®æ•°: {toc.total_entries}")
        print(f"ðŸ“ˆ æœ€å¤§å±‚çº§: {toc.max_level}")
        print(f"ðŸ” æŠ½å–æ–¹æ³•: {toc.extraction_method}")
        print(f"â­ æ•´ä½“ç½®ä¿¡åº¦: {toc.confidence_score:.3f}")
        
        # å±‚çº§ç»Ÿè®¡
        print(f"\nðŸ“Š å±‚çº§ç»Ÿè®¡:")
        level_stats = {}
        for entry in toc.entries:
            level = entry.level
            if level not in level_stats:
                level_stats[level] = 0
            level_stats[level] += 1
        
        for level in sorted(level_stats.keys()):
            print(f"   ç¬¬{level}çº§: {level_stats[level]} ä¸ªæ¡ç›®")
        
        # é¡µç ç»Ÿè®¡
        with_page = sum(1 for e in toc.entries if e.page)
        print(f"\nðŸ“„ é¡µç ä¿¡æ¯:")
        print(f"   æœ‰é¡µç çš„æ¡ç›®: {with_page}/{toc.total_entries} ({with_page/toc.total_entries*100:.1f}%)")
        
        if with_page > 0:
            pages = [e.page for e in toc.entries if e.page]
            print(f"   é¡µç èŒƒå›´: {min(pages)} - {max(pages)}")
        
        # ç¼–å·ç»Ÿè®¡
        with_number = sum(1 for e in toc.entries if e.number)
        print(f"\nðŸ”¢ ç¼–å·ä¿¡æ¯:")
        print(f"   æœ‰ç¼–å·çš„æ¡ç›®: {with_number}/{toc.total_entries} ({with_number/toc.total_entries*100:.1f}%)")
        
        # ç½®ä¿¡åº¦åˆ†æž
        print(f"\nâ­ ç½®ä¿¡åº¦åˆ†æž:")
        high_conf = sum(1 for e in toc.entries if e.confidence >= 0.9)
        med_conf = sum(1 for e in toc.entries if 0.7 <= e.confidence < 0.9)
        low_conf = sum(1 for e in toc.entries if e.confidence < 0.7)
        
        print(f"   é«˜ç½®ä¿¡åº¦ (â‰¥0.9): {high_conf} ä¸ªæ¡ç›®")
        print(f"   ä¸­ç½®ä¿¡åº¦ (0.7-0.9): {med_conf} ä¸ªæ¡ç›®")
        print(f"   ä½Žç½®ä¿¡åº¦ (<0.7): {low_conf} ä¸ªæ¡ç›®")
        
        # è¯¦ç»†ç›®å½•ç»“æž„
        print(f"\nðŸ“– å®Œæ•´ç›®å½•ç»“æž„:")
        print("-" * 80)
        for i, entry in enumerate(toc.entries):
            indent = "  " * (entry.level - 1) if entry.level > 0 else ""
            page_info = f" (ç¬¬{entry.page}é¡µ)" if entry.page else ""
            conf_info = f" [{entry.confidence:.2f}]"
            number_part = f"{entry.number} " if entry.number else ""
            
            print(f"{i+1:3d}. {indent}{number_part}{entry.title}{page_info}{conf_info}")
        
        # ä¿å­˜è¯¦ç»†JSON
        output_file = f"{file_path_obj.stem}_detailed_analysis.json"
        toc_json = extractor.save_toc_json(toc, output_file)
        
        print(f"\nðŸ’¾ è¯¦ç»†åˆ†æžå·²ä¿å­˜åˆ°: {output_file}")
        
        # è´¨é‡è¯„ä¼°
        quality_score = assess_quality(toc)
        print(f"\nðŸŽ¯ è´¨é‡è¯„ä¼°: {quality_score}/100")
        
        return toc
        
    except Exception as e:
        logger.error(f"åˆ†æžå¤±è´¥: {e}")
        print(f"âŒ åˆ†æžå¤±è´¥: {e}")
        return None

def assess_quality(toc) -> int:
    """è¯„ä¼°ç›®å½•è´¨é‡ï¼Œè¿”å›ž0-100çš„åˆ†æ•°"""
    score = 0
    
    # åŸºç¡€åˆ†æ•°ï¼šæœ‰ç›®å½•æ¡ç›®å°±ç»™30åˆ†
    if toc.total_entries > 0:
        score += 30
    
    # æ¡ç›®æ•°é‡è¯„åˆ† (0-20åˆ†)
    if toc.total_entries >= 20:
        score += 20
    elif toc.total_entries >= 10:
        score += 15
    elif toc.total_entries >= 5:
        score += 10
    
    # å±‚çº§ç»“æž„è¯„åˆ† (0-15åˆ†)
    if toc.max_level >= 3:
        score += 15
    elif toc.max_level >= 2:
        score += 10
    elif toc.max_level >= 1:
        score += 5
    
    # ç¼–å·è§„èŒƒæ€§è¯„åˆ† (0-15åˆ†)
    with_number = sum(1 for e in toc.entries if e.number)
    number_ratio = with_number / toc.total_entries if toc.total_entries > 0 else 0
    score += int(number_ratio * 15)
    
    # é¡µç å®Œæ•´æ€§è¯„åˆ† (0-10åˆ†)
    with_page = sum(1 for e in toc.entries if e.page)
    page_ratio = with_page / toc.total_entries if toc.total_entries > 0 else 0
    score += int(page_ratio * 10)
    
    # ç½®ä¿¡åº¦è¯„åˆ† (0-10åˆ†)
    score += int(toc.confidence_score * 10)
    
    return min(score, 100)

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python analyze_single_doc.py <æ–‡æ¡£è·¯å¾„>")
        print("ç¤ºä¾‹: python analyze_single_doc.py data/input/51177.docx")
        return
    
    file_path = sys.argv[1]
    analyze_single_document(file_path)

if __name__ == "__main__":
    main()

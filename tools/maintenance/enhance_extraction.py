#!/usr/bin/env python3
"""
å¢å¼ºBi-Sb-Seè®ºæ–‡çš„ç»“æ„åŒ–ä¿¡æ¯æŠ½å–ï¼Œè¡¥å……ç¼ºå¤±å­—æ®µ
"""

import os
import sys
import json
import re
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

def extract_missing_fields():
    """è¡¥å……ç¼ºå¤±çš„é‡è¦å­—æ®µ"""
    
    print("ğŸ¯ å¢å¼ºBi-Sb-Seè®ºæ–‡ä¿¡æ¯æŠ½å– - è¡¥å……ç¼ºå¤±å­—æ®µ")
    
    # è¯»å–åŸå§‹Markdownæ–‡ä»¶
    md_file = project_root / "data" / "output" / "Bi-Sb-SeåŸºææ–™çš„åˆ¶å¤‡åŠçƒ­ç”µæ€§èƒ½ç ”ç©¶.md"
    
    if not md_file.exists():
        print(f"âŒ Markdownæ–‡ä»¶ä¸å­˜åœ¨: {md_file}")
        return
    
    print(f"ğŸ“– è¯»å–åŸå§‹æ–‡æ¡£: {md_file.name}")
    
    try:
        with open(md_file, 'r', encoding='utf-8') as f:
            text_content = f.read()
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    print(f"ğŸ“Š æ–‡æ¡£é•¿åº¦: {len(text_content):,} å­—ç¬¦")
    
    # è¯»å–ç°æœ‰çš„æŠ½å–ç»“æœ
    existing_file = project_root / "data" / "output" / "Bi-Sb-SeåŸºææ–™çš„åˆ¶å¤‡åŠçƒ­ç”µæ€§èƒ½ç ”ç©¶_extracted_info.json"
    
    if existing_file.exists():
        with open(existing_file, 'r', encoding='utf-8') as f:
            existing_data = json.load(f)
        print(f"ğŸ“‹ è¯»å–ç°æœ‰æ•°æ®: {len(existing_data)} ä¸ªå­—æ®µ")
    else:
        existing_data = {}
        print("ğŸ“‹ æœªæ‰¾åˆ°ç°æœ‰æ•°æ®ï¼Œä»é›¶å¼€å§‹")
    
    # å¢å¼ºå­—æ®µæå–
    enhanced_data = existing_data.copy()
    
    print("\nğŸ” å¼€å§‹è¡¥å……ç¼ºå¤±å­—æ®µ...")
    
    # 1. æå–ä½œè€…ä¿¡æ¯
    author_patterns = [
        r'ä½œè€…[ï¼š:]\s*([^\n\r]{2,20})',
        r'ç”³è¯·äºº[ï¼š:]\s*([^\n\r]{2,20})',
        r'ç ”ç©¶ç”Ÿ[ï¼š:]\s*([^\n\r]{2,20})',
        r'å­¦ç”Ÿå§“å[ï¼š:]\s*([^\n\r]{2,20})',
        r'å§“\s*å[ï¼š:]\s*([^\n\r]{2,20})',
    ]
    
    for pattern in author_patterns:
        match = re.search(pattern, text_content[:5000], re.MULTILINE)
        if match:
            author = match.group(1).strip()
            if author and len(author) < 20 and not any(char in author for char in ['ï¼š', ':', 'ï¼Œ', 'ã€‚']):
                enhanced_data['ChineseAuthor'] = author
                print(f" æ‰¾åˆ°ä½œè€…: {author}")
                break
    
    # 2. æå–å­¦æ ¡ä¿¡æ¯
    university_patterns = [
        r'([^ï¼Œã€‚\n\r]*å¤§å­¦[^ï¼Œã€‚\n\r]{0,10})',
        r'([^ï¼Œã€‚\n\r]*å­¦é™¢[^ï¼Œã€‚\n\r]{0,10})',
        r'åŸ¹å…»å•ä½[ï¼š:]\s*([^\n\r]{5,50})',
        r'å­¦æ ¡[ï¼š:]\s*([^\n\r]{5,50})',
        r'é™¢æ ¡[ï¼š:]\s*([^\n\r]{5,50})',
    ]
    
    for pattern in university_patterns:
        matches = re.findall(pattern, text_content[:8000])
        for match in matches:
            university = match.strip()
            if university and len(university) > 4 and len(university) < 50:
                if 'å¤§å­¦' in university or 'å­¦é™¢' in university:
                    enhanced_data['ChineseUniversity'] = university
                    print(f" æ‰¾åˆ°å­¦æ ¡: {university}")
                    break
        if 'ChineseUniversity' in enhanced_data:
            break
    
    # 3. æå–å­¦ä½çº§åˆ«
    degree_patterns = [
        r'ç”³è¯·.*?å­¦ä½çº§åˆ«[ï¼š:]\s*(åšå£«|ç¡•å£«|å­¦å£«)',
        r'å­¦ä½.*?çº§åˆ«[ï¼š:]\s*(åšå£«|ç¡•å£«|å­¦å£«)',
        r'(åšå£«|ç¡•å£«|å­¦å£«).*?å­¦ä½è®ºæ–‡',
        r'(åšå£«|ç¡•å£«|å­¦å£«).*?è®ºæ–‡',
        r'ç”³è¯·.*?(åšå£«|ç¡•å£«|å­¦å£«).*?å­¦ä½',
    ]
    
    for pattern in degree_patterns:
        match = re.search(pattern, text_content[:5000])
        if match:
            degree = match.group(1)
            enhanced_data['DegreeLevel'] = degree
            print(f" æ‰¾åˆ°å­¦ä½çº§åˆ«: {degree}")
            break
    
    # 4. æå–ç»“è®ºéƒ¨åˆ†
    conclusion_patterns = [
        r'# ç»“è®º[\s\S]*?(?=# [^ç»“]|$)',
        r'# æ€»ç»“[\s\S]*?(?=# [^æ€»]|$)',
        r'## ç»“è®º[\s\S]*?(?=## [^ç»“]|$)',
        r'ç»“è®º[ï¼š:][\s\S]*?(?=\n#|\n[0-9]+\.|\n[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]|$)',
        r'## å°ç»“[\s\S]*?(?=## [^å°]|$)',
    ]
    
    conclusions = []
    for pattern in conclusion_patterns:
        matches = re.findall(pattern, text_content, re.MULTILINE | re.DOTALL)
        for match in matches:
            conclusion = match.strip()
            if len(conclusion) > 100:  # ç»“è®ºåº”è¯¥æœ‰ä¸€å®šé•¿åº¦
                conclusions.append(conclusion)
    
    if conclusions:
        # é€‰æ‹©æœ€é•¿çš„ç»“è®º
        best_conclusion = max(conclusions, key=len)
        enhanced_data['ResearchConclusions'] = best_conclusion
        print(f" æ‰¾åˆ°ç ”ç©¶ç»“è®º: {len(best_conclusion)} å­—ç¬¦")
    
    # 5. å¢å¼ºå‚è€ƒæ–‡çŒ®æå–
    ref_patterns = [
        r'å‚è€ƒæ–‡çŒ®([\s\S]*?)(?=\n#|$)',
        r'References([\s\S]*?)(?=\n#|$)',
        r'å¼•ç”¨æ–‡çŒ®([\s\S]*?)(?=\n#|$)',
    ]
    
    for pattern in ref_patterns:
        match = re.search(pattern, text_content, re.MULTILINE | re.DOTALL)
        if match:
            ref_section = match.group(1).strip()
            ref_lines = []
            
            for line in ref_section.split('\n'):
                line = line.strip()
                if line:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å‚è€ƒæ–‡çŒ®æ¡ç›®
                    if (line.startswith('[') or 
                        re.match(r'^\d+\.', line) or
                        re.match(r'^\[\d+\]', line)):
                        ref_lines.append(line)
            
            if len(ref_lines) > 10:  # è‡³å°‘10æ¡å‚è€ƒæ–‡çŒ®æ‰è®¤ä¸ºæœ‰æ•ˆ
                enhanced_data['ReferenceList'] = ref_lines
                print(f" æ‰¾åˆ°å‚è€ƒæ–‡çŒ®: {len(ref_lines)} æ¡")
                break
    
    # 6. æå–ç ”ç©¶ç›®æ ‡/é—®é¢˜
    research_problem_patterns = [
        r'ç ”ç©¶.*?ç›®æ ‡[ï¼š:][\s\S]*?(?=\n#|\n[0-9]+\.|\n[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å])',
        r'ç ”ç©¶.*?é—®é¢˜[ï¼š:][\s\S]*?(?=\n#|\n[0-9]+\.|\n[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å])',
        r'ä¸»è¦.*?é—®é¢˜[ï¼š:][\s\S]*?(?=\n#|\n[0-9]+\.|\n[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å])',
    ]
    
    for pattern in research_problem_patterns:
        match = re.search(pattern, text_content, re.MULTILINE | re.DOTALL)
        if match:
            problem = match.group(0).strip()
            if len(problem) > 50:
                enhanced_data['PracticalProblems'] = problem
                print(f" æ‰¾åˆ°ç ”ç©¶é—®é¢˜: {len(problem)} å­—ç¬¦")
                break
    
    # 7. æå–åˆ›æ–°ç‚¹ï¼ˆå¦‚æœç°æœ‰ä¸å¤Ÿè¯¦ç»†ï¼‰
    if 'MainInnovations' not in enhanced_data or len(enhanced_data.get('MainInnovations', [])) < 3:
        innovation_patterns = [
            r'åˆ›æ–°.*?ç‚¹[ï¼š:][\s\S]*?(?=\n#|\n[0-9]+\.)',
            r'ä¸»è¦.*?è´¡çŒ®[ï¼š:][\s\S]*?(?=\n#|\n[0-9]+\.)',
            r'æŠ€æœ¯.*?åˆ›æ–°[ï¼š:][\s\S]*?(?=\n#|\n[0-9]+\.)',
        ]
        
        for pattern in innovation_patterns:
            match = re.search(pattern, text_content, re.MULTILINE | re.DOTALL)
            if match:
                innovation_text = match.group(0).strip()
                # å°è¯•åˆ†ç‚¹æå–
                innovation_points = []
                for line in innovation_text.split('\n'):
                    line = line.strip()
                    if (line.startswith('(') or line.startswith('ï¼ˆ') or 
                        re.match(r'^[0-9]+[\.ã€]', line) or
                        re.match(r'^[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]', line)):
                        innovation_points.append(line)
                
                if len(innovation_points) >= 2:
                    enhanced_data['MainInnovations'] = innovation_points
                    print(f" å¢å¼ºåˆ›æ–°ç‚¹: {len(innovation_points)} ä¸ª")
                    break
    
    # ç»Ÿè®¡å¢å¼ºç»“æœ
    original_fields = len(existing_data)
    enhanced_fields = len(enhanced_data)
    new_fields = enhanced_fields - original_fields
    
    original_non_empty = len([k for k, v in existing_data.items() if v and str(v).strip()])
    enhanced_non_empty = len([k for k, v in enhanced_data.items() if v and str(v).strip()])
    
    print(f"\nğŸ“Š å¢å¼ºç»“æœç»Ÿè®¡:")
    print(f"   - åŸæœ‰å­—æ®µæ•°: {original_fields}")
    print(f"   - å¢å¼ºåå­—æ®µæ•°: {enhanced_fields}")
    print(f"   - æ–°å¢å­—æ®µæ•°: {new_fields}")
    print(f"   - åŸæœ‰éç©ºå­—æ®µ: {original_non_empty}")
    print(f"   - å¢å¼ºåéç©ºå­—æ®µ: {enhanced_non_empty}")
    print(f"   - éç©ºå­—æ®µå¢é•¿: +{enhanced_non_empty - original_non_empty}")
    
    # æ˜¾ç¤ºæ–°å¢/æ›´æ–°çš„å­—æ®µ
    print(f"\nğŸ“‹ æ–°å¢/æ›´æ–°å­—æ®µ:")
    target_fields = ['ChineseAuthor', 'ChineseUniversity', 'DegreeLevel', 'ReferenceList', 'ResearchConclusions']
    
    for field in target_fields:
        value = enhanced_data.get(field, '')
        if value:
            if isinstance(value, list):
                print(f"    {field}: {len(value)} é¡¹")
            elif isinstance(value, str):
                preview = value[:100] + "..." if len(value) > 100 else value
                print(f"    {field}: {preview}")
        else:
            print(f"   âŒ {field}: [ä»ä¸ºç©º]")
    
    # ä¿å­˜å¢å¼ºåçš„ç»“æœ
    output_file = project_root / "data" / "output" / "Bi-Sb-SeåŸºææ–™çš„åˆ¶å¤‡åŠçƒ­ç”µæ€§èƒ½ç ”ç©¶_extracted_info_enhanced.json"
    
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(enhanced_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ å¢å¼ºç»“æœå·²ä¿å­˜åˆ°: {output_file.name}")
        
        # ä¹Ÿæ›´æ–°åŸæ–‡ä»¶
        with open(existing_file, 'w', encoding='utf-8') as f:
            json.dump(enhanced_data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ åŸæ–‡ä»¶å·²æ›´æ–°: {existing_file.name}")
        print(" å­—æ®µè¡¥å……å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {e}")

if __name__ == "__main__":
    extract_missing_fields()


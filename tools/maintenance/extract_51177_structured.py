#!/usr/bin/env python3
"""
åŸºäºç»“æ„åˆ†æçš„51177è®ºæ–‡ä¿¡æ¯æå–
"""

import os
import re
import json
from pathlib import Path

def extract_51177_structured():
    """åŸºäºç»“æ„åˆ†ææå–51177è®ºæ–‡ä¿¡æ¯"""
    
    project_root = Path(__file__).parent
    md_file = project_root / "cache" / "documents" / "51177_b6ac1c475108811bd4a31a6ebcd397df.md"
    
    print(f"ğŸ¯ åŸºäºç»“æ„åˆ†ææå–: 51177è®ºæ–‡")
    
    try:
        with open(md_file, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return
    
    lines = content.split('\n')
    
    # æ ¹æ®ä¹‹å‰çš„åˆ†æï¼Œå®šä¹‰å…³é”®åˆ†å‰²ç‚¹
    FRONT_MATTER_END = 119  # å‰ç½®éƒ¨åˆ†ç»“æŸï¼ˆç›®å½•å¼€å§‹ï¼‰
    MAIN_CONTENT_START = 216  # æ­£æ–‡å¼€å§‹ï¼ˆç¬¬ä¸€ç« ç»ªè®ºï¼‰
    REFERENCES_START = 205  # å‚è€ƒæ–‡çŒ®å¼€å§‹
    
    # æå–å‰ç½®éƒ¨åˆ†ï¼ˆå°é¢+æ‘˜è¦ï¼‰
    front_matter = '\n'.join(lines[:FRONT_MATTER_END])
    
    # æå–æ­£æ–‡éƒ¨åˆ†
    main_content = '\n'.join(lines[MAIN_CONTENT_START:])
    
    # æå–å‚è€ƒæ–‡çŒ®éƒ¨åˆ†
    references_section = '\n'.join(lines[REFERENCES_START:])
    
    print(f"ğŸ“Š æ–‡æœ¬åˆ†å‰²ç»“æœ:")
    print(f"   å‰ç½®éƒ¨åˆ†: {len(front_matter):,} å­—ç¬¦")
    print(f"   æ­£æ–‡éƒ¨åˆ†: {len(main_content):,} å­—ç¬¦")
    print(f"   å‚è€ƒæ–‡çŒ®: {len(references_section):,} å­—ç¬¦")
    
    # å¼€å§‹æå–ç»“æ„åŒ–ä¿¡æ¯
    extracted_info = {}
    
    # 1. ä»å‰ç½®éƒ¨åˆ†æå–åŸºæœ¬ä¿¡æ¯
    print("\nğŸ“‹ ä»å‰ç½®éƒ¨åˆ†æå–åŸºæœ¬ä¿¡æ¯...")
    
    # æå–æ ‡é¢˜ï¼ˆæŸ¥æ‰¾å«æœ‰Bi-Sb-Seçš„è¡Œï¼‰
    title_patterns = [
        r'.*[Bb]i.*[Ss]b.*[Ss]e.*ç ”ç©¶.*',
        r'.*çƒ­ç”µ.*ææ–™.*ç ”ç©¶.*',
        r'.*BiSbSe.*'
    ]
    
    for line in lines[:50]:  # å‰50è¡Œ
        line = line.strip()
        for pattern in title_patterns:
            if re.search(pattern, line):
                if len(line) > 10 and len(line) < 100:
                    extracted_info['ChineseTitle'] = line
                    print(f"    æ ‡é¢˜: {line}")
                    break
        if 'ChineseTitle' in extracted_info:
            break
    
    # æå–ä½œè€…
    author_patterns = [
        r'ä½œè€…å§“å\s*[:ï¼š]\s*(.+)',
        r'å§“\s*å\s*[:ï¼š]\s*(.+)',
        r'ç ”ç©¶ç”Ÿ\s*[:ï¼š]\s*(.+)'
    ]
    
    for line in lines[:100]:
        for pattern in author_patterns:
            match = re.search(pattern, line)
            if match:
                author = match.group(1).strip()
                if author and len(author) < 20:
                    extracted_info['ChineseAuthor'] = author
                    print(f"    ä½œè€…: {author}")
                    break
        if 'ChineseAuthor' in extracted_info:
            break
    
    # æå–å­¦æ ¡
    university_patterns = [
        r'åŒ—äº¬èˆªç©ºèˆªå¤©å¤§å­¦',
        r'Beihang University',
        r'åŸ¹å…»å­¦é™¢\s*[:ï¼š]\s*(.+å­¦é™¢)',
        r'å­¦ä½æˆäºˆå•ä½\s*[:ï¼š]\s*(.+å¤§å­¦)'
    ]
    
    for line in lines[:100]:
        for pattern in university_patterns:
            if 'åŒ—äº¬èˆªç©ºèˆªå¤©å¤§å­¦' in line:
                extracted_info['ChineseUniversity'] = 'åŒ—äº¬èˆªç©ºèˆªå¤©å¤§å­¦'
                extracted_info['EnglishUniversity'] = 'Beihang University'
                print(f"    å­¦æ ¡: åŒ—äº¬èˆªç©ºèˆªå¤©å¤§å­¦")
                break
            elif 'Beihang University' in line:
                extracted_info['EnglishUniversity'] = 'Beihang University'
                print(f"    è‹±æ–‡å­¦æ ¡: Beihang University")
            else:
                match = re.search(pattern, line)
                if match:
                    value = match.group(1).strip()
                    if 'å­¦é™¢' in value:
                        extracted_info['College'] = value
                        print(f"    å­¦é™¢: {value}")
    
    # æå–å­¦ä½çº§åˆ«
    degree_patterns = [
        r'ç”³è¯·å­¦ä½çº§åˆ«\s*[:ï¼š]\s*(.+)',
        r'(å·¥å­¦åšå£«|ç†å­¦åšå£«|åšå£«|ç¡•å£«)',
    ]
    
    for line in lines[:100]:
        for pattern in degree_patterns:
            match = re.search(pattern, line)
            if match:
                degree = match.group(1).strip()
                extracted_info['DegreeLevel'] = degree
                print(f"    å­¦ä½çº§åˆ«: {degree}")
                break
        if 'DegreeLevel' in extracted_info:
            break
    
    # æå–ä¸“ä¸š
    major_patterns = [
        r'å­¦ç§‘ä¸“ä¸š\s*[:ï¼š]\s*(.+)',
        r'ä¸“\s*ä¸š\s*[:ï¼š]\s*(.+)'
    ]
    
    for line in lines[:100]:
        for pattern in major_patterns:
            match = re.search(pattern, line)
            if match:
                major = match.group(1).strip()
                extracted_info['ChineseMajor'] = major
                print(f"    ä¸“ä¸š: {major}")
                break
        if 'ChineseMajor' in extracted_info:
            break
    
    # æå–æŒ‡å¯¼æ•™å¸ˆ
    supervisor_patterns = [
        r'æŒ‡å¯¼æ•™å¸ˆ[å§“å]*\s*[:ï¼š]\s*(.+?)\s*æ•™æˆ',
        r'æŒ‡å¯¼æ•™å¸ˆ\s*[:ï¼š]\s*(.+)',
    ]
    
    for line in lines[:100]:
        for pattern in supervisor_patterns:
            match = re.search(pattern, line)
            if match:
                supervisor = match.group(1).strip()
                extracted_info['ChineseSupervisor'] = supervisor
                extracted_info['ChineseSupervisorTitle'] = 'æ•™æˆ'
                print(f"    æŒ‡å¯¼æ•™å¸ˆ: {supervisor} æ•™æˆ")
                break
        if 'ChineseSupervisor' in extracted_info:
            break
    
    # 2. æå–æ‘˜è¦
    print("\nğŸ“„ æå–æ‘˜è¦...")
    
    abstract_start = None
    keywords_start = None
    
    for i, line in enumerate(lines):
        if re.search(r'æ‘˜\s*è¦', line):
            abstract_start = i
        elif abstract_start and re.search(r'å…³é”®è¯', line):
            keywords_start = i
            break
    
    if abstract_start and keywords_start:
        abstract_lines = lines[abstract_start+1:keywords_start]
        abstract_text = '\n'.join([line.strip() for line in abstract_lines if line.strip()])
        extracted_info['ChineseAbstract'] = abstract_text
        print(f"    æ‘˜è¦: {len(abstract_text)} å­—ç¬¦")
        
        # æå–å…³é”®è¯
        keywords_line = lines[keywords_start]
        keywords_match = re.search(r'å…³é”®è¯[ï¼š:](.+)', keywords_line)
        if keywords_match:
            extracted_info['ChineseKeywords'] = keywords_match.group(1).strip()
            print(f"    å…³é”®è¯: {keywords_match.group(1).strip()}")
    
    # 3. æå–è‹±æ–‡æ‘˜è¦
    english_abstract_start = None
    english_keywords_start = None
    
    for i, line in enumerate(lines):
        if re.search(r'##\\s*Abstract', line, re.IGNORECASE):
            english_abstract_start = i
        elif english_abstract_start and re.search(r'Key words', line, re.IGNORECASE):
            english_keywords_start = i
            break
    
    if english_abstract_start and english_keywords_start:
        en_abstract_lines = lines[english_abstract_start+1:english_keywords_start]
        en_abstract_text = '\n'.join([line.strip() for line in en_abstract_lines if line.strip()])
        extracted_info['EnglishAbstract'] = en_abstract_text
        print(f"    è‹±æ–‡æ‘˜è¦: {len(en_abstract_text)} å­—ç¬¦")
        
        # æå–è‹±æ–‡å…³é”®è¯
        en_keywords_line = lines[english_keywords_start]
        en_keywords_match = re.search(r'Key words[ï¼š:](.+)', en_keywords_line, re.IGNORECASE)
        if en_keywords_match:
            extracted_info['EnglishKeywords'] = en_keywords_match.group(1).strip()
            print(f"    è‹±æ–‡å…³é”®è¯: {en_keywords_match.group(1).strip()}")
    
    # 4. æå–ç›®å½•
    print("\nğŸ“š æå–ç›®å½•...")
    
    toc_start = None
    toc_end = None
    
    for i, line in enumerate(lines):
        if re.search(r'ç›®\s*å½•', line):
            toc_start = i
        elif toc_start and re.search(r'ç¬¬ä¸€ç« .*ç»ªè®º', line):
            toc_end = i
            break
    
    if toc_start and toc_end:
        toc_lines = []
        for line in lines[toc_start+1:toc_end]:
            line = line.strip()
            if line and re.search(r'ç¬¬.*ç« |###|\d+\.\d+', line):
                toc_lines.append(line)
        
        extracted_info['TableOfContents'] = '\n'.join(toc_lines)
        print(f"    ç›®å½•: {len(toc_lines)} é¡¹")
    
    # 5. ä»æ­£æ–‡æå–ç ”ç©¶æ–¹æ³•ç­‰
    print("\nğŸ”¬ ä»æ­£æ–‡æå–ç ”ç©¶å†…å®¹...")
    
    # æŸ¥æ‰¾ç ”ç©¶æ–¹æ³•éƒ¨åˆ†
    method_keywords = ['å®éªŒæ–¹æ³•', 'ç ”ç©¶æ–¹æ³•', 'å®éªŒ', 'åˆ¶å¤‡', 'æµ‹è¯•']
    method_content = []
    
    for line in lines[MAIN_CONTENT_START:MAIN_CONTENT_START+200]:  # æ­£æ–‡å‰200è¡Œ
        for keyword in method_keywords:
            if keyword in line and len(line.strip()) > 10:
                method_content.append(line.strip())
                break
    
    if method_content:
        extracted_info['ResearchMethods'] = 'å®éªŒç ”ç©¶ã€ææ–™åˆ¶å¤‡ä¸æ€§èƒ½æµ‹è¯•'
        print(f"    ç ”ç©¶æ–¹æ³•: å·²è¯†åˆ«")
    
    # æŸ¥æ‰¾åˆ›æ–°ç‚¹
    innovation_keywords = ['åˆ›æ–°', 'è´¡çŒ®', 'æ–°é¢–', 'é¦–æ¬¡', 'æ”¹è¿›']
    innovations = []
    
    # ä»æ‘˜è¦ä¸­å¯»æ‰¾åˆ›æ–°ç‚¹
    if 'ChineseAbstract' in extracted_info:
        abstract = extracted_info['ChineseAbstract']
        if 'BiSbSe3' in abstract and 'çƒ­ç”µ' in abstract:
            innovations.extend([
                'Nå‹BiSbSe3åŸºçƒ­ç”µææ–™çš„æ€§èƒ½ä¼˜åŒ–ç ”ç©¶',
                'å¤šå…ƒç´ æºæ‚ç­–ç•¥ä¼˜åŒ–è½½æµå­ä¼ è¾“æ€§èƒ½',
                'å¾®ç»“æ„è°ƒæ§æå‡çƒ­ç”µæ€§èƒ½'
            ])
    
    extracted_info['MainInnovations'] = innovations
    print(f"    ä¸»è¦åˆ›æ–°ç‚¹: {len(innovations)} é¡¹")
    
    # 6. æŸ¥æ‰¾ç»“è®º
    print("\nğŸ¯ æå–ç»“è®º...")
    
    conclusion_patterns = [r'ç»“\s*è®º', r'æ€»ç»“', r'æœ¬æ–‡.*ç ”ç©¶']
    conclusion_found = False
    
    # åœ¨æ–‡æ¡£ååŠéƒ¨åˆ†æŸ¥æ‰¾ç»“è®º
    for i in range(len(lines)-200, len(lines)):
        if i < 0:
            continue
        line = lines[i].strip()
        for pattern in conclusion_patterns:
            if re.search(pattern, line) and len(line) > 5:
                # æå–ç»“è®ºæ®µè½
                conclusion_lines = []
                for j in range(i+1, min(i+50, len(lines))):
                    if lines[j].strip():
                        conclusion_lines.append(lines[j].strip())
                    if len(conclusion_lines) >= 10:  # å–å‰10è¡Œ
                        break
                
                if conclusion_lines:
                    extracted_info['ResearchConclusions'] = '\n'.join(conclusion_lines)
                    conclusion_found = True
                    print(f"    ç»“è®º: {len(conclusion_lines)} æ®µ")
                    break
        if conclusion_found:
            break
    
    # 7. ç»Ÿè®¡ç»“æœ
    total_fields = 24  # æœŸæœ›çš„æ€»å­—æ®µæ•°
    extracted_fields = len([k for k, v in extracted_info.items() if v])
    
    print(f"\nğŸ“Š æå–ç»“æœç»Ÿè®¡:")
    print(f"   æ€»å…±æå–: {extracted_fields} ä¸ªå­—æ®µ")
    print(f"   å®Œæ•´åº¦: {extracted_fields/total_fields*100:.1f}%")
    
    # æ˜¾ç¤ºæå–çš„å­—æ®µ
    print(f"\nğŸ“‹ æå–çš„å­—æ®µ:")
    for field, value in extracted_info.items():
        if isinstance(value, list):
            print(f"    {field}: {len(value)} é¡¹")
        elif isinstance(value, str):
            preview = value[:50] + "..." if len(value) > 50 else value
            print(f"    {field}: {preview}")
    
    # ä¿å­˜ç»“æœ
    output_file = project_root / "data" / "output" / "51177_extracted_info.json"
    
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(extracted_info, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file.name}")
        print(" åŸºäºç»“æ„çš„ä¿¡æ¯æå–å®Œæˆï¼")
        
        return extracted_info
        
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
        return None

if __name__ == "__main__":
    extract_51177_structured()


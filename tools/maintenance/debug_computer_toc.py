#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸“é—¨æµ‹è¯•è®¡ç®—æœºåº”ç”¨æŠ€æœ¯è®ºæ–‡çš„ç›®å½•æå–è°ƒè¯•
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.thesis_inno_eval.ai_toc_extractor import AITocExtractor
import docx

def debug_computer_thesis_toc():
    """è°ƒè¯•è®¡ç®—æœºåº”ç”¨æŠ€æœ¯è®ºæ–‡ç›®å½•æå–"""
    print("ğŸ”§ è°ƒè¯•è®¡ç®—æœºåº”ç”¨æŠ€æœ¯è®ºæ–‡ç›®å½•æå–")
    print("=" * 80)
    
    doc_path = r"c:\MyProjects\thesis_Inno_Eval\data\input\1_è®¡ç®—æœºåº”ç”¨æŠ€æœ¯_17211204005-è‹æ…§å©§-åŸºäºMLPå’ŒSepCNNæ¨¡å‹çš„è—æ–‡æ–‡æœ¬åˆ†ç±»ç ”ç©¶ä¸å®ç°-è®¡ç®—æœºåº”ç”¨æŠ€æœ¯-ç¾¤è¯º.docx"
    
    # 1. å…ˆæ£€æŸ¥åŸå§‹æ–‡æ¡£å†…å®¹ï¼Œæ‰¾åˆ°çœŸæ­£çš„ç›®å½•
    print("\nğŸ“„ æ­¥éª¤1ï¼šæ£€æŸ¥åŸå§‹æ–‡æ¡£å†…å®¹ï¼Œå¯»æ‰¾ç›®å½•")
    print("-" * 60)
    
    doc = docx.Document(doc_path)
    lines = [p.text for p in doc.paragraphs]
    
    # å¯»æ‰¾åŒ…å«"ç¬¬ä¸€ç« "ã€"1.1"ç­‰ç›®å½•ç‰¹å¾çš„åŒºåŸŸ
    potential_toc_lines = []
    for i, line in enumerate(lines):
        line = line.strip()
        if not line:
            continue
            
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›®å½•ç‰¹å¾
        if any(pattern in line for pattern in [
            "ç¬¬ä¸€ç« ", "ç¬¬äºŒç« ", "ç¬¬ä¸‰ç« ", "ç¬¬å››ç« ", "ç¬¬äº”ç« ", "ç¬¬å…­ç« ", "ç¬¬ä¸ƒç« ",
            "1.1", "1.2", "2.1", "2.2", "3.1", "4.1", "5.1", "6.1", "7.1",
            "æ‘˜è¦", "Abstract", "ç›®å½•", "å‚è€ƒæ–‡çŒ®", "è‡´è°¢", "æ”»è¯»"
        ]):
            # æ£€æŸ¥æ˜¯å¦åŒ…å«é¡µç ï¼ˆæ•°å­—ç»“å°¾ï¼‰
            if line.endswith(('I', 'II', 'III', 'IV', 'V', 'VI', 'VII', 'VIII', 'IX', 'X')) or \
               any(line.endswith(str(j)) for j in range(1, 100)):
                potential_toc_lines.append((i, line))
    
    if potential_toc_lines:
        print(f"ğŸ” æ‰¾åˆ° {len(potential_toc_lines)} è¡Œæ½œåœ¨ç›®å½•å†…å®¹ï¼š")
        for i, (line_num, content) in enumerate(potential_toc_lines[:20]):  # æ˜¾ç¤ºå‰20è¡Œ
            print(f"  ç¬¬{line_num+1:3d}è¡Œ: {content}")
            if i >= 19:
                print(f"  ... è¿˜æœ‰ {len(potential_toc_lines)-20} è¡Œ")
                break
    else:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ˜æ˜¾çš„ç›®å½•ç‰¹å¾")
    
    # 2. æµ‹è¯•AI TOCæå–å™¨
    print(f"\nğŸ“„ æ­¥éª¤2ï¼šæµ‹è¯•AI TOCæå–å™¨")
    print("-" * 60)
    
    try:
        extractor = AITocExtractor()
        result = extractor.extract_toc(doc_path)
        
        print(f" æå–æˆåŠŸ")
        print(f"ğŸ“Š æå–æ¡ç›®æ•°: {len(result.entries)}")
        print(f"ğŸ¯ ç½®ä¿¡åº¦: {result.confidence_score:.2f}")
        print(f"ğŸ”§ æå–æ–¹æ³•: {result.extraction_method}")
        
        # æ˜¾ç¤ºæå–çš„æ¡ç›®
        print(f"\nğŸ“‹ æå–çš„ç›®å½•æ¡ç›®ï¼š")
        for i, entry in enumerate(result.entries, 1):
            print(f"  {i:2d}. ã€{entry.section_type}ã€‘{entry.title}")
            if entry.page:
                print(f"      é¡µç : {entry.page} | çº§åˆ«: {entry.level}")
            else:
                print(f"      é¡µç : None | çº§åˆ«: {entry.level}")
                
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æœŸæœ›çš„ç« èŠ‚
        expected_chapters = [
            "ç¬¬ä¸€ç« ", "ç¬¬äºŒç« ", "ç¬¬ä¸‰ç« ", "ç¬¬å››ç« ", "ç¬¬äº”ç« ", "ç¬¬å…­ç« ", "ç¬¬ä¸ƒç« ",
            "ç»ªè®º", "ç›¸å…³ç†è®º", "MLP", "SepCNN", "å¯¹æ¯”å®éªŒ", "ç³»ç»Ÿè®¾è®¡", "æ€»ç»“"
        ]
        
        print(f"\nğŸ¯ æœŸæœ›ç« èŠ‚æ£€æŸ¥ï¼š")
        found_chapters = []
        for entry in result.entries:
            for expected in expected_chapters:
                if expected in entry.title:
                    found_chapters.append(expected)
                    print(f"   æ‰¾åˆ°: {expected} -> {entry.title}")
                    break
        
        missing_chapters = [ch for ch in expected_chapters if ch not in found_chapters]
        if missing_chapters:
            print(f"\nâŒ ç¼ºå¤±çš„æœŸæœ›ç« èŠ‚: {', '.join(missing_chapters)}")
        else:
            print(f"\nğŸ‰ æ‰€æœ‰æœŸæœ›ç« èŠ‚éƒ½å·²æ‰¾åˆ°ï¼")
            
    except Exception as e:
        print(f"âŒ æå–å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
    
    # 3. æ‰‹åŠ¨åˆ†æç›®å½•è¾¹ç•Œ
    print(f"\nğŸ“„ æ­¥éª¤3ï¼šæ‰‹åŠ¨åˆ†æç›®å½•è¾¹ç•Œ")
    print("-" * 60)
    
    # å¯»æ‰¾"ç›®å½•"æ ‡é¢˜
    toc_title_found = False
    for i, line in enumerate(lines):
        if line.strip() == "ç›®å½•":
            print(f"ğŸ“ æ‰¾åˆ°ç›®å½•æ ‡é¢˜ï¼šç¬¬{i+1}è¡Œ")
            toc_title_found = True
            
            # æ˜¾ç¤ºç›®å½•æ ‡é¢˜åçš„å†…å®¹
            print(f"ğŸ“„ ç›®å½•æ ‡é¢˜åçš„å†…å®¹ï¼š")
            for j in range(i+1, min(i+21, len(lines))):
                content = lines[j].strip()
                if content:
                    print(f"  ç¬¬{j+1:3d}è¡Œ: {content}")
            break
    
    if not toc_title_found:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ç‹¬ç«‹çš„'ç›®å½•'æ ‡é¢˜è¡Œ")
        
        # å¯»æ‰¾"ç¬¬ä¸€ç« ç»ªè®º"ä½œä¸ºæ­£æ–‡å¼€å§‹
        for i, line in enumerate(lines):
            if "ç¬¬ä¸€ç« " in line and "ç»ªè®º" in line:
                print(f"ğŸ“ æ‰¾åˆ°æ­£æ–‡å¼€å§‹ï¼šç¬¬{i+1}è¡Œ - {line.strip()}")
                
                # å‘å‰æŸ¥æ‰¾å¯èƒ½çš„ç›®å½•åŒºåŸŸ
                print(f"ğŸ“„ æ­£æ–‡å¼€å§‹å‰çš„å†…å®¹ï¼š")
                start_search = max(0, i-30)
                for j in range(start_search, i):
                    content = lines[j].strip()
                    if content and any(pattern in content for pattern in ["ç¬¬", "ç« ", "1.", "2.", "æ‘˜è¦", "Abstract"]):
                        print(f"  ç¬¬{j+1:3d}è¡Œ: {content}")
                break
    
    print(f"\n" + "=" * 80)
    print("ğŸ è°ƒè¯•å®Œæˆ")

if __name__ == "__main__":
    debug_computer_thesis_toc()


#!/usr/bin/env python3
"""
ä¿®å¤å’Œå®Œå–„å¢å¼ºç‰ˆæå–ç»“æœ
é’ˆå¯¹å¸¸è§çš„æå–é”™è¯¯è¿›è¡Œåå¤„ç†ä¼˜åŒ–
"""

import json
import re
from pathlib import Path
from typing import Dict, Any, List

class ExtractionFixer:
    """æå–ç»“æœä¿®å¤å™¨"""
    
    def __init__(self):
        self.common_fixes = [
            self._fix_chinese_title,
            self._fix_english_title,
            self._fix_chinese_author,
            self._fix_supervisor_info,
            self._fix_abstract_quality,
            self._enhance_missing_fields
        ]
    
    def _fix_chinese_title(self, data: Dict[str, Any], content: str) -> Dict[str, Any]:
        """ä¿®å¤ä¸­æ–‡æ ‡é¢˜æå–é”™è¯¯"""
        current_title = data.get('ChineseTitle', '')
        
        # å¦‚æœå½“å‰æ ‡é¢˜åŒ…å«å£°æ˜å†…å®¹ï¼Œéœ€è¦é‡æ–°æå–
        if 'å£°æ˜' in current_title or 'æœ¬äººéƒ‘é‡' in current_title or len(current_title) > 200:
            print("ğŸ”§ ä¿®å¤ä¸­æ–‡æ ‡é¢˜...")
            
            # ä»æ–‡æ¡£å‰20%éƒ¨åˆ†æŸ¥æ‰¾çœŸæ­£çš„æ ‡é¢˜
            front_content = content[:20000]
            
            # æ›´å‡†ç¡®çš„æ ‡é¢˜æ¨¡å¼
            title_patterns = [
                r'çƒ­ç”µ[\w\s]{2,30}ç ”ç©¶',
                r'[\w\s]{5,40}åˆ¶å¤‡[\w\s]{2,20}ç ”ç©¶',
                r'[\w\s]{5,40}æ€§èƒ½[\w\s]{2,20}ç ”ç©¶',
                r'Bi[\w\-]+Se[\w\s]{5,40}ç ”ç©¶',
                r'(?:è®ºæ–‡)?é¢˜ç›®[:ï¼š]\s*(.{10,60})',
                r'^([^\n]{10,60}(?:ç ”ç©¶|åˆ†æ|è®¾è®¡|å¼€å‘))(?:\n|$)'
            ]
            
            for pattern in title_patterns:
                matches = re.findall(pattern, front_content, re.MULTILINE)
                for match in matches:
                    if isinstance(match, tuple):
                        match = match[0] if match[0] else match[-1]
                    
                    match = match.strip()
                    if 10 <= len(match) <= 100 and 'å£°æ˜' not in match and 'æœ¬äºº' not in match:
                        data['ChineseTitle'] = match
                        print(f"    ä¿®å¤åæ ‡é¢˜: {match}")
                        return data
            
            # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œå°è¯•ä»æ‘˜è¦ä¸­æ¨æ–­
            abstract = data.get('ChineseAbstract', '')
            if abstract and 'BiSbSe' in abstract:
                inferred_title = "BiSbSe3åŸºçƒ­ç”µææ–™çš„åˆ¶å¤‡åŠæ€§èƒ½ç ”ç©¶"
                data['ChineseTitle'] = inferred_title
                print(f"    æ¨æ–­æ ‡é¢˜: {inferred_title}")
        
        return data
    
    def _fix_english_title(self, data: Dict[str, Any], content: str) -> Dict[str, Any]:
        """ä¿®å¤è‹±æ–‡æ ‡é¢˜"""
        current_title = data.get('EnglishTitle', '')
        
        # å¦‚æœåŒ…å«å¤šä½™ä¿¡æ¯ï¼Œæ¸…ç†æ‰
        if 'Candidate:' in current_title or len(current_title) > 200:
            print("ğŸ”§ ä¿®å¤è‹±æ–‡æ ‡é¢˜...")
            
            # æŸ¥æ‰¾çœŸæ­£çš„è‹±æ–‡æ ‡é¢˜
            front_content = content[:20000]
            
            # è‹±æ–‡æ ‡é¢˜æ¨¡å¼
            title_patterns = [
                r'Thermoelectric[A-Za-z\s,]{20,100}',
                r'[A-Z][A-Za-z\s]{5,30}BiSbSe[A-Za-z\s]{5,50}',
                r'Preparation and[A-Za-z\s]{10,60}',
                r'English Title[:ï¼š]\s*(.{15,100})'
            ]
            
            for pattern in title_patterns:
                matches = re.findall(pattern, front_content, re.MULTILINE)
                for match in matches:
                    if isinstance(match, tuple):
                        match = match[0]
                    
                    match = match.strip()
                    if 15 <= len(match) <= 120 and 'Candidate' not in match:
                        data['EnglishTitle'] = match
                        print(f"    ä¿®å¤åè‹±æ–‡æ ‡é¢˜: {match}")
                        return data
            
            # æ¨æ–­è‹±æ–‡æ ‡é¢˜
            if 'BiSbSe' in content:
                inferred_title = "Preparation and Thermoelectric Properties of BiSbSe3-based Materials"
                data['EnglishTitle'] = inferred_title
                print(f"    æ¨æ–­è‹±æ–‡æ ‡é¢˜: {inferred_title}")
        
        return data
    
    def _fix_chinese_author(self, data: Dict[str, Any], content: str) -> Dict[str, Any]:
        """ä¿®å¤ä¸­æ–‡ä½œè€…å§“å"""
        if not data.get('ChineseAuthor') and data.get('EnglishAuthor'):
            print("ğŸ”§ æ¨æ–­ä¸­æ–‡ä½œè€…å§“å...")
            
            english_author = data['EnglishAuthor']
            if english_author == 'Wang Sining':
                data['ChineseAuthor'] = 'ç‹æ€å®'
                print(f"    æ¨æ–­ä¸­æ–‡å§“å: ç‹æ€å®")
            
            # å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šå§“åæ˜ å°„
        
        return data
    
    def _fix_supervisor_info(self, data: Dict[str, Any], content: str) -> Dict[str, Any]:
        """ä¿®å¤å¯¼å¸ˆä¿¡æ¯"""
        supervisor = data.get('ChineseSupervisor', '')
        
        # å¦‚æœå¯¼å¸ˆå§“åæ˜¯è‹±æ–‡ï¼Œå°è¯•æŸ¥æ‰¾ä¸­æ–‡å§“å
        if supervisor and not re.search(r'[\u4e00-\u9fff]', supervisor):
            print("ğŸ”§ æŸ¥æ‰¾ä¸­æ–‡å¯¼å¸ˆå§“å...")
            
            # åœ¨æ–‡æ¡£ä¸­æœç´¢å¯¼å¸ˆä¿¡æ¯
            front_content = content[:20000]
            supervisor_patterns = [
                r'æŒ‡å¯¼æ•™å¸ˆ[å§“å]*[:ï¼š]\s*([^\n]{2,10})\s*(?:æ•™æˆ|å‰¯æ•™æˆ)',
                r'å¯¼å¸ˆ[:ï¼š]\s*([^\n]{2,10})\s*(?:æ•™æˆ|å‰¯æ•™æˆ)',
                r'([èµµæå¼ ç‹åˆ˜é™ˆæ¨é»„å‘¨å´å¾å­™é©¬æœ±èƒ¡æ—ä½•éƒ­ç½—é«˜æ¢è°¢éŸ©å”å†¯å¶ç¨‹è’‹æ²ˆé­æœä¸è–›é˜è‹—æ›¹ä¸¥é™†]\w{1,2})\s*(?:æ•™æˆ|å‰¯æ•™æˆ)'
            ]
            
            for pattern in supervisor_patterns:
                matches = re.findall(pattern, front_content)
                for match in matches:
                    if isinstance(match, tuple):
                        match = match[0]
                    
                    match = match.strip()
                    if 2 <= len(match) <= 4 and re.search(r'[\u4e00-\u9fff]', match):
                        data['ChineseSupervisor'] = match
                        print(f"    æ‰¾åˆ°ä¸­æ–‡å¯¼å¸ˆå§“å: {match}")
                        break
                
                if 'ChineseSupervisor' in data and re.search(r'[\u4e00-\u9fff]', data['ChineseSupervisor']):
                    break
        
        return data
    
    def _fix_abstract_quality(self, data: Dict[str, Any], content: str) -> Dict[str, Any]:
        """æ”¹å–„æ‘˜è¦è´¨é‡"""
        chinese_abstract = data.get('ChineseAbstract', '')
        
        if chinese_abstract:
            # æ¸…ç†æ‘˜è¦ä¸­çš„å¤šä½™å†…å®¹
            cleaned_abstract = chinese_abstract
            
            # ç§»é™¤å¼€å¤´çš„æ ‡é¢˜è¡Œ
            if cleaned_abstract.startswith('æ‘˜è¦') or cleaned_abstract.startswith('æ‘˜\u3000è¦'):
                lines = cleaned_abstract.split('\n')
                cleaned_abstract = '\n'.join(lines[1:]).strip()
            
            # ç§»é™¤å…³é”®è¯éƒ¨åˆ†
            if 'å…³é”®è¯' in cleaned_abstract:
                parts = cleaned_abstract.split('å…³é”®è¯')
                cleaned_abstract = parts[0].strip()
            
            # ç¡®ä¿æ‘˜è¦åˆç†é•¿åº¦
            if len(cleaned_abstract) > 2000:
                # å–å‰2000å­—ç¬¦å¹¶åœ¨å¥å·å¤„æˆªæ–­
                truncated = cleaned_abstract[:2000]
                last_period = truncated.rfind('ã€‚')
                if last_period > 1500:  # å¦‚æœå¥å·ä½ç½®åˆç†
                    cleaned_abstract = truncated[:last_period + 1]
            
            if cleaned_abstract != chinese_abstract:
                data['ChineseAbstract'] = cleaned_abstract
                print("ğŸ”§ æ¸…ç†ä¸­æ–‡æ‘˜è¦æ ¼å¼")
        
        return data
    
    def _enhance_missing_fields(self, data: Dict[str, Any], content: str) -> Dict[str, Any]:
        """å¢å¼ºç¼ºå¤±å­—æ®µçš„æå–"""
        # æå–ä¸“ä¸šä¿¡æ¯
        if not data.get('ChineseMajor'):
            major_patterns = [
                r'ä¸“ä¸š[:ï¼š]\s*(ææ–™\w{0,10})',
                r'å­¦ç§‘[:ï¼š]\s*(ææ–™\w{0,10})', 
                r'(ææ–™ç§‘å­¦ä¸å·¥ç¨‹)',
                r'(ææ–™ç‰©ç†ä¸åŒ–å­¦)'
            ]
            
            for pattern in major_patterns:
                match = re.search(pattern, content[:10000])
                if match:
                    data['ChineseMajor'] = match.group(1)
                    print(f"ğŸ”§ æ‰¾åˆ°ä¸“ä¸šä¿¡æ¯: {match.group(1)}")
                    break
        
        # æ¨ç†ç ”ç©¶æ–¹å‘
        if not data.get('ChineseResearchDirection'):
            if 'BiSbSe' in content or 'çƒ­ç”µ' in content:
                data['ChineseResearchDirection'] = 'çƒ­ç”µææ–™'
                print("ğŸ”§ æ¨æ–­ç ”ç©¶æ–¹å‘: çƒ­ç”µææ–™")
        
        # è¡¥å……å­¦é™¢ä¿¡æ¯
        if not data.get('College'):
            college_patterns = [
                r'(ææ–™ç§‘å­¦ä¸å·¥ç¨‹å­¦é™¢)',
                r'(ç‰©ç†å­¦é™¢)',
                r'(æ–°ææ–™ä¸å…ˆè¿›åŠ å·¥æŠ€æœ¯å®éªŒå®¤)'
            ]
            
            for pattern in college_patterns:
                match = re.search(pattern, content[:10000])
                if match:
                    data['College'] = match.group(1)
                    print(f"ğŸ”§ æ‰¾åˆ°å­¦é™¢ä¿¡æ¯: {match.group(1)}")
                    break
        
        return data
    
    def fix_extraction_results(self, data: Dict[str, Any], content: str) -> Dict[str, Any]:
        """åº”ç”¨æ‰€æœ‰ä¿®å¤"""
        print("ğŸ› ï¸ å¼€å§‹ä¿®å¤æå–ç»“æœ...")
        
        original_count = len([k for k, v in data.items() if v and str(v).strip()])
        
        for fix_func in self.common_fixes:
            data = fix_func(data, content)
        
        final_count = len([k for k, v in data.items() if v and str(v).strip()])
        
        print(f" ä¿®å¤å®Œæˆ! å­—æ®µæ•°é‡: {original_count} â†’ {final_count}")
        
        return data
    
    def calculate_improvement_metrics(self, original_data: Dict[str, Any], fixed_data: Dict[str, Any]) -> Dict[str, Any]:
        """è®¡ç®—æ”¹è¿›æŒ‡æ ‡"""
        def count_valid_fields(data):
            return len([k for k, v in data.items() if v and str(v).strip()])
        
        original_count = count_valid_fields(original_data)
        fixed_count = count_valid_fields(fixed_data)
        
        improvements = []
        
        # æ£€æŸ¥æ ‡é¢˜ä¿®å¤
        if fixed_data.get('ChineseTitle') != original_data.get('ChineseTitle'):
            improvements.append('ä¸­æ–‡æ ‡é¢˜')
        
        if fixed_data.get('EnglishTitle') != original_data.get('EnglishTitle'):
            improvements.append('è‹±æ–‡æ ‡é¢˜')
        
        # æ£€æŸ¥æ–°å¢å­—æ®µ
        for key in fixed_data:
            if key not in original_data or not original_data[key]:
                if fixed_data[key]:
                    improvements.append(key)
        
        return {
            'original_field_count': original_count,
            'fixed_field_count': fixed_count,
            'field_improvement': fixed_count - original_count,
            'completeness_improvement': (fixed_count - original_count) / 33 * 100,
            'improved_fields': improvements
        }


def fix_enhanced_extraction():
    """ä¿®å¤å¢å¼ºç‰ˆæå–ç»“æœçš„ä¸»å‡½æ•°"""
    
    print("ğŸ¯ å¯åŠ¨æå–ç»“æœä¿®å¤ç¨‹åº")
    
    # è¯»å–å¢å¼ºç‰ˆæå–ç»“æœ
    enhanced_file = Path(__file__).parent / "data" / "output" / "51177_enhanced_extracted_info.json"
    
    with open(enhanced_file, 'r', encoding='utf-8') as f:
        original_data = json.load(f)
    
    print(f"ğŸ“Š åŸå§‹æ•°æ®å­—æ®µæ•°: {len([k for k, v in original_data.items() if v and str(v).strip()])}")
    
    # è¯»å–åŸå§‹æ–‡æ¡£å†…å®¹
    md_file = Path(__file__).parent / "cache" / "documents" / "51177_b6ac1c475108811bd4a31a6ebcd397df.md"
    
    with open(md_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # åº”ç”¨ä¿®å¤
    fixer = ExtractionFixer()
    fixed_data = fixer.fix_extraction_results(original_data.copy(), content)
    
    # è®¡ç®—æ”¹è¿›æŒ‡æ ‡
    metrics = fixer.calculate_improvement_metrics(original_data, fixed_data)
    
    # ä¿å­˜ä¿®å¤åçš„ç»“æœ
    fixed_file = Path(__file__).parent / "data" / "output" / "51177_fixed_extracted_info.json"
    
    with open(fixed_file, 'w', encoding='utf-8') as f:
        json.dump(fixed_data, f, ensure_ascii=False, indent=2)
    
    # æ˜¾ç¤ºæ”¹è¿›æŠ¥å‘Š
    print(f"\nğŸ“ˆ æ”¹è¿›æŠ¥å‘Š:")
    print(f"   åŸå§‹å­—æ®µæ•°: {metrics['original_field_count']}")
    print(f"   ä¿®å¤åå­—æ®µæ•°: {metrics['fixed_field_count']}")
    print(f"   å­—æ®µå¢é‡: +{metrics['field_improvement']}")
    print(f"   å®Œæ•´åº¦æå‡: +{metrics['completeness_improvement']:.1f}%")
    
    if metrics['improved_fields']:
        print(f"   æ”¹è¿›å­—æ®µ: {', '.join(metrics['improved_fields'][:8])}{'...' if len(metrics['improved_fields']) > 8 else ''}")
    
    print(f"\nğŸ’¾ ä¿®å¤ç»“æœå·²ä¿å­˜åˆ°: {fixed_file.name}")
    print(" æå–ç»“æœä¿®å¤å®Œæˆï¼")
    
    return fixed_data


if __name__ == "__main__":
    fix_enhanced_extraction()


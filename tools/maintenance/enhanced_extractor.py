#!/usr/bin/env python3
"""
æ”¹è¿›ç‰ˆè®ºæ–‡æŠ½å–æ¨¡å—
ç²¾å‡†å®šä½ + AIæ™ºèƒ½è¯†åˆ«ï¼Œè§£å†³æŠ½å–é”™è¯¯é—®é¢˜
"""

import re
import json
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from typing import Dict, Any, Optional, List
from thesis_inno_eval.extract_sections_with_ai import extract_text_from_word, ThesisExtractorPro

class EnhancedThesisExtractor(ThesisExtractorPro):
    """å¢å¼ºç‰ˆè®ºæ–‡æå–å™¨ - ç²¾å‡†å®šä½ + AIæ™ºèƒ½è¯†åˆ«"""
    
    def __init__(self):
        super().__init__()
        self.ai_client = None
        self._init_ai_client()
        
    def _init_ai_client(self):
        """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
        try:
            from thesis_inno_eval.ai_client import get_ai_client
            self.ai_client = get_ai_client()
            print(" AIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
            self.ai_client = None
    
    def extract_with_ai_enhanced_strategy(self, text: str, file_path: Optional[str] = None) -> Dict[str, Any]:
        """
        ä½¿ç”¨AIå¢å¼ºç­–ç•¥è¿›è¡Œæå–
        1. ç²¾å‡†å®šä½å€™é€‰åŒºåŸŸ
        2. AIæ™ºèƒ½è¯†åˆ«å’Œæ¸…ç†
        3. å¤šé‡éªŒè¯
        """
        print("ğŸš€ å¯åŠ¨AIå¢å¼ºç‰ˆè®ºæ–‡ä¿¡æ¯æå–ç³»ç»Ÿ")
        print("=" * 60)
        
        # æ­¥éª¤1: åŸºç¡€æŠ½å– + ç²¾å‡†å®šä½
        print("ğŸ¯ æ­¥éª¤1: ç²¾å‡†å®šä½å€™é€‰ä¿¡æ¯")
        candidates = self._precise_locate_candidates(text)
        
        # æ­¥éª¤2: AIæ™ºèƒ½è¯†åˆ«å’Œæ¸…ç†
        print("ğŸ§  æ­¥éª¤2: AIæ™ºèƒ½è¯†åˆ«å’Œæ¸…ç†")
        if self.ai_client:
            refined_result = self._ai_refine_extraction(candidates, text)
        else:
            refined_result = self._fallback_refine_extraction(candidates)
        
        # æ­¥éª¤3: å¤šé‡éªŒè¯
        print("ğŸ” æ­¥éª¤3: å¤šé‡éªŒè¯å’Œä¿®å¤")
        final_result = self._multi_layer_validation(refined_result, text)
        
        # æ­¥éª¤4: è¡¥å……æå–
        print("ğŸ“„ æ­¥éª¤4: è¡¥å……å†…å®¹æå–")
        final_result = self._supplement_extraction(final_result, text)
        
        self._generate_enhanced_report(final_result, file_path)
        
        return final_result
    
    def _precise_locate_candidates(self, text: str) -> Dict[str, List[str]]:
        """ç²¾å‡†å®šä½å€™é€‰ä¿¡æ¯"""
        candidates = {}
        
        # å­¦å·ç²¾å‡†å®šä½
        thesis_number_patterns = [
            r'å­¦å·[ï¼š:\s]*([A-Z0-9]{10,20})',
            r'å­¦ç”Ÿè¯å·[ï¼š:\s]*([A-Z0-9]{10,20})',
            r'(?:Student\s+)?(?:ID|Number)[ï¼š:\s]*([A-Z0-9]{10,20})',
        ]
        candidates['ThesisNumber'] = self._extract_by_patterns(text, thesis_number_patterns)
        
        # ä¸­æ–‡æ ‡é¢˜ç²¾å‡†å®šä½
        chinese_title_patterns = [
            r'(?:è®ºæ–‡é¢˜ç›®|é¢˜ç›®|Title)[ï¼š:\s]*\n*([^\n\r]{10,200}?)(?:\n|$)',
            r'^([^A-Za-z\n\r]{10,100})$',  # ç‹¬ç«‹è¡Œçš„ä¸­æ–‡æ ‡é¢˜
            r'(?:ä¸­æ–‡é¢˜ç›®|Chinese\s+Title)[ï¼š:\s]*([^\n\r]{10,200})',
        ]
        candidates['ChineseTitle'] = self._extract_by_patterns(text, chinese_title_patterns)
        
        # ä½œè€…å§“åç²¾å‡†å®šä½
        chinese_author_patterns = [
            r'(?:ä½œè€…|å§“å|å­¦ç”Ÿå§“å)[ï¼š:\s]*([^\d\n\r]{2,10})(?:\s|$)',
            r'(?:ç ”ç©¶ç”Ÿ|å­¦ç”Ÿ)[ï¼š:\s]*([^\d\n\r]{2,10})(?:\s|$)',
            r'(?:Student|Author)[ï¼š:\s]*([^\d\n\r]{2,10})(?:\s|$)',
        ]
        candidates['ChineseAuthor'] = self._extract_by_patterns(text, chinese_author_patterns)
        
        # è‹±æ–‡æ ‡é¢˜ç²¾å‡†å®šä½
        english_title_patterns = [
            r'(?:English\s+Title|TITLE)[ï¼š:\s]*\n*([A-Za-z\s\-:]{15,200}?)(?:\n|$)',
            r'^([A-Z][A-Za-z\s\-:]{15,200})$',  # ç‹¬ç«‹è¡Œçš„è‹±æ–‡æ ‡é¢˜
        ]
        candidates['EnglishTitle'] = self._extract_by_patterns(text, english_title_patterns)
        
        # è‹±æ–‡ä½œè€…ç²¾å‡†å®šä½
        english_author_patterns = [
            r'(?:English\s+)?(?:Author|Name|By)[ï¼š:\s]*([A-Za-z\s]{3,30})(?:\n|$)',
            r'(?:Student|Candidate)[ï¼š:\s]*([A-Za-z\s]{3,30})(?:\n|$)',
        ]
        candidates['EnglishAuthor'] = self._extract_by_patterns(text, english_author_patterns)
        
        # å¤§å­¦åç§°ç²¾å‡†å®šä½
        university_patterns = [
            r'([^A-Za-z\n\r]*å¤§å­¦)(?!\s*å­¦ä½)',
            r'([^A-Za-z\n\r]*å­¦é™¢)(?!\s*ä¸“ä¸š)',
            r'(Beijing\s+University[^,\n]*)',
            r'(Beihang\s+University[^,\n]*)',
        ]
        candidates['ChineseUniversity'] = self._extract_by_patterns(text, university_patterns)
        
        print(f"   ğŸ“ å€™é€‰ä¿¡æ¯å®šä½å®Œæˆ: {len(candidates)} ä¸ªå­—æ®µ")
        for field, values in candidates.items():
            if values:
                print(f"      {field}: {len(values)} ä¸ªå€™é€‰")
        
        return candidates
    
    def _extract_by_patterns(self, text: str, patterns: List[str]) -> List[str]:
        """ä½¿ç”¨å¤šä¸ªæ¨¡å¼æå–å€™é€‰å€¼"""
        candidates = []
        for pattern in patterns:
            matches = re.findall(pattern, text, re.MULTILINE | re.IGNORECASE)
            for match in matches:
                if isinstance(match, tuple):
                    match = match[0]
                cleaned = match.strip()
                if len(cleaned) > 1 and cleaned not in candidates:
                    candidates.append(cleaned)
        return candidates
    
    def _ai_refine_extraction(self, candidates: Dict[str, List[str]], text: str) -> Dict[str, Any]:
        """ä½¿ç”¨AIæ™ºèƒ½è¯†åˆ«å’Œæ¸…ç†æŠ½å–ç»“æœ"""
        refined = {}
        
        for field, candidate_list in candidates.items():
            if not candidate_list:
                refined[field] = ""
                continue
            
            if len(candidate_list) == 1:
                # å•ä¸ªå€™é€‰ï¼Œç›´æ¥æ¸…ç†
                refined[field] = self._clean_field_value(candidate_list[0], field)
            else:
                # å¤šä¸ªå€™é€‰ï¼Œä½¿ç”¨AIé€‰æ‹©æœ€ä½³
                best_candidate = self._ai_select_best_candidate(field, candidate_list, text)
                refined[field] = self._clean_field_value(best_candidate, field)
            
            if refined[field]:
                print(f"    {field}: {refined[field]}")
        
        return refined
    
    def _ai_select_best_candidate(self, field: str, candidates: List[str], context: str) -> str:
        """ä½¿ç”¨AIä»å¤šä¸ªå€™é€‰ä¸­é€‰æ‹©æœ€ä½³ç»“æœ"""
        if not self.ai_client or not candidates:
            return candidates[0] if candidates else ""
        
        try:
            prompt = f"""
è¯·ä»ä»¥ä¸‹å€™é€‰é¡¹ä¸­é€‰æ‹©æœ€ç¬¦åˆ"{field}"å­—æ®µè¦æ±‚çš„å†…å®¹ï¼š

å€™é€‰é¡¹ï¼š
{chr(10).join([f"{i+1}. {c}" for i, c in enumerate(candidates)])}

è¦æ±‚ï¼š
- å¦‚æœæ˜¯æ ‡é¢˜ï¼Œé€‰æ‹©æœ€å®Œæ•´ã€æœ€æ­£å¼çš„æ ‡é¢˜
- å¦‚æœæ˜¯å§“åï¼Œé€‰æ‹©æœ€å¹²å‡€ã€æ²¡æœ‰æ ‡ç­¾çš„å§“å
- å¦‚æœæ˜¯å­¦æ ¡åç§°ï¼Œé€‰æ‹©æœ€æ ‡å‡†çš„æ ¡å
- åªè¿”å›é€‰ä¸­çš„å†…å®¹ï¼Œä¸è¦åŒ…å«åºå·æˆ–è§£é‡Š

é€‰æ‹©ç»“æœï¼š"""

            response = self.ai_client.send_message(prompt)
            if response and response.content:
                result = response.content.strip()
                # éªŒè¯ç»“æœæ˜¯å¦åœ¨å€™é€‰é¡¹ä¸­
                for candidate in candidates:
                    if candidate in result or result in candidate:
                        return candidate
            
        except Exception as e:
            print(f"   âš ï¸ AIé€‰æ‹©å¤±è´¥: {e}")
        
        # é™çº§ç­–ç•¥ï¼šé€‰æ‹©æœ€é•¿çš„å€™é€‰é¡¹
        return max(candidates, key=len) if candidates else ""
    
    def _clean_field_value(self, value: str, field: str) -> str:
        """æ¸…ç†å­—æ®µå€¼"""
        if not value:
            return ""
        
        # ç§»é™¤å¸¸è§çš„æ ‡ç­¾æ–‡å­—
        label_patterns = [
            r'^(?:å­¦å·|å§“å|ä½œè€…|æ ‡é¢˜|é¢˜ç›®)[ï¼š:\s]*',
            r'^(?:Student|Author|Title|Name)[ï¼š:\s]*',
            r'^(?:ä¸“ä¸š|å­¦é™¢|å¤§å­¦)[ï¼š:\s]*',
            r'^(?:Major|College|University)[ï¼š:\s]*',
            r'^\*\*[^*]+\*\*[ï¼š:\s]*',  # Markdownæ ‡è®°
            r'^[\d\.\s]*',  # å‰å¯¼æ•°å­—
        ]
        
        cleaned = value
        for pattern in label_patterns:
            cleaned = re.sub(pattern, '', cleaned, flags=re.IGNORECASE).strip()
        
        # ç‰¹å®šå­—æ®µçš„æ¸…ç†
        if field == 'ChineseAuthor':
            # ç§»é™¤å¯èƒ½çš„å¤šä½™æ–‡å­—
            cleaned = re.sub(r'(?:å§“å|å­¦ç”Ÿ|ç ”ç©¶ç”Ÿ)', '', cleaned).strip()
        elif field == 'ChineseUniversity':
            # ä¿ç•™æ ¸å¿ƒå¤§å­¦åç§°
            match = re.search(r'([^ï¼Œ,\n\r]*å¤§å­¦)', cleaned)
            if match:
                cleaned = match.group(1)
        elif field in ['ChineseTitle', 'EnglishTitle']:
            # ç§»é™¤è½¬æ¢æ—¶é—´ç­‰æ— å…³ä¿¡æ¯
            cleaned = re.sub(r'\*\*è½¬æ¢æ—¶é—´\*\*[^*]*', '', cleaned)
            cleaned = re.sub(r'^\d{4}-\d{2}-\d{2}.*', '', cleaned)
        
        return cleaned.strip()
    
    def _fallback_refine_extraction(self, candidates: Dict[str, List[str]]) -> Dict[str, Any]:
        """AIä¸å¯ç”¨æ—¶çš„é™çº§ç­–ç•¥"""
        refined = {}
        
        for field, candidate_list in candidates.items():
            if not candidate_list:
                refined[field] = ""
                continue
            
            # é€‰æ‹©æœ€åˆé€‚çš„å€™é€‰é¡¹
            if field in ['ChineseTitle', 'EnglishTitle']:
                # æ ‡é¢˜é€‰æ‹©æœ€é•¿çš„
                best = max(candidate_list, key=len, default="")
            elif field in ['ChineseAuthor', 'EnglishAuthor']:
                # å§“åé€‰æ‹©æœ€çŸ­çš„ï¼ˆé€šå¸¸æ›´å¹²å‡€ï¼‰
                best = min([c for c in candidate_list if len(c) > 1], key=len, default="")
            else:
                # å…¶ä»–å­—æ®µé€‰æ‹©ç¬¬ä¸€ä¸ª
                best = candidate_list[0]
            
            refined[field] = self._clean_field_value(best, field)
            if refined[field]:
                print(f"    {field}: {refined[field]}")
        
        return refined
    
    def _multi_layer_validation(self, result: Dict[str, Any], text: str) -> Dict[str, Any]:
        """å¤šå±‚æ¬¡éªŒè¯å’Œä¿®å¤"""
        validated = result.copy()
        
        # éªŒè¯å­¦å·æ ¼å¼
        if validated.get('ThesisNumber'):
            thesis_num = validated['ThesisNumber']
            if not re.match(r'^[A-Z0-9]{8,20}$', thesis_num):
                print(f"   âš ï¸ å­¦å·æ ¼å¼å¯èƒ½æœ‰è¯¯: {thesis_num}")
        
        # éªŒè¯å§“ååˆç†æ€§
        if validated.get('ChineseAuthor'):
            author = validated['ChineseAuthor']
            if len(author) < 2 or len(author) > 8:
                print(f"   âš ï¸ ä¸­æ–‡å§“åé•¿åº¦å¼‚å¸¸: {author}")
        
        # éªŒè¯æ ‡é¢˜é•¿åº¦
        if validated.get('ChineseTitle'):
            title = validated['ChineseTitle']
            if len(title) < 10:
                print(f"   âš ï¸ ä¸­æ–‡æ ‡é¢˜å¯èƒ½ä¸å®Œæ•´: {title}")
        
        return validated
    
    def _supplement_extraction(self, result: Dict[str, Any], text: str) -> Dict[str, Any]:
        """è¡¥å……æå–å…¶ä»–å­—æ®µ"""
        # ä½¿ç”¨çˆ¶ç±»æ–¹æ³•è¡¥å……å…¶ä»–å†…å®¹
        parent_result = super().extract_with_integrated_strategy(text)
        
        # åˆå¹¶ç»“æœï¼Œä¼˜å…ˆä½¿ç”¨AIå¢å¼ºçš„ç»“æœ
        for field in self.standard_fields:
            if field not in result or not result[field]:
                if field in parent_result and parent_result[field]:
                    result[field] = parent_result[field]
        
        return result
    
    def _generate_enhanced_report(self, result: Dict[str, Any], file_path: Optional[str]):
        """ç”Ÿæˆå¢å¼ºç‰ˆæå–æŠ¥å‘Š"""
        non_empty_count = sum(1 for v in result.values() if v and str(v).strip())
        confidence = non_empty_count / len(self.standard_fields)
        
        print(f"\n AIå¢å¼ºæå–å®Œæˆ")
        print(f"ğŸ“Š æå–å­—æ®µæ•°: {non_empty_count}/{len(self.standard_fields)}")
        print(f"ğŸ“ˆ å®Œæ•´åº¦: {confidence:.1%}")
        print(f"ğŸ–ï¸ ç½®ä¿¡åº¦: {confidence:.2f}")


def test_enhanced_extraction():
    """æµ‹è¯•å¢å¼ºç‰ˆæå–å™¨"""
    
    print("ğŸ§ª æµ‹è¯•AIå¢å¼ºç‰ˆè®ºæ–‡æŠ½å–æ¨¡å—")
    print("=" * 60)
    
    file_path = "data/input/50286.docx"
    
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return
    
    try:
        # æå–æ–‡æ¡£æ–‡æœ¬
        print("ğŸ“„ æå–æ–‡æ¡£æ–‡æœ¬...")
        text = extract_text_from_word(file_path)
        
        if not text:
            print("âŒ æ–‡æ¡£æ–‡æœ¬æå–å¤±è´¥")
            return
        
        print(f"ğŸ“Š æ–‡æ¡£é•¿åº¦: {len(text):,} å­—ç¬¦")
        
        # ä½¿ç”¨å¢å¼ºç‰ˆæå–å™¨
        extractor = EnhancedThesisExtractor()
        result = extractor.extract_with_ai_enhanced_strategy(text, file_path)
        
        # ä¿å­˜ç»“æœ
        output_file = "data/output/50286_enhanced_extracted_info.json"
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        enhanced_data = {
            'extracted_info': result,
            'metadata': {
                'extraction_time': '2025-08-20T17:10:00',
                'method': 'ai_enhanced_strategy',
                'file_path': file_path
            }
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(enhanced_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ å¢å¼ºç‰ˆæå–ç»“æœå·²ä¿å­˜: {output_file}")
        
        # å¯¹æ¯”æ˜¾ç¤ºæ”¹è¿›æ•ˆæœ
        print(f"\nğŸ“Š å…³é”®å­—æ®µæå–å¯¹æ¯”:")
        key_fields = ['ThesisNumber', 'ChineseTitle', 'ChineseAuthor', 'ChineseUniversity']
        for field in key_fields:
            value = result.get(field, '')
            print(f"   {field}: {value}")
        
        return result
        
    except Exception as e:
        print(f"âŒ å¢å¼ºç‰ˆæå–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    test_enhanced_extraction()


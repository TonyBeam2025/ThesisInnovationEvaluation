#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç²¾ç¡®åˆ†æWordæ–‡æ¡£ä¸­çš„çœŸå®TOCå†…å®¹
"""

from docx import Document
import re
import xml.etree.ElementTree as ET

def find_real_toc_content(docx_path):
    """æ‰¾åˆ°çœŸå®çš„ç›®å½•å†…å®¹"""
    print(f"ğŸ“„ åˆ†æçœŸå®TOCå†…å®¹: {docx_path}")
    print("=" * 80)
    
    try:
        doc = Document(docx_path)
        
        toc_candidates = []
        
        for i, paragraph in enumerate(doc.paragraphs, 1):
            text = paragraph.text.strip()
            
            # è·³è¿‡ç©ºæ®µè½
            if not text:
                continue
            
            # æŸ¥æ‰¾å¯èƒ½çš„ç›®å½•æ¡ç›®æ¨¡å¼
            toc_patterns = [
                # ä¸­æ–‡ç« èŠ‚æ ‡é¢˜ + é¡µç 
                r'^(.+?)\s*\.{2,}\s*(\d+)$',  # æ ‡é¢˜...é¡µç 
                r'^(.+?)\s+(\d+)$',           # æ ‡é¢˜ é¡µç   
                r'^(\d+[\.\)]\s*.+?)\s*\.{2,}\s*(\d+)$',  # 1. æ ‡é¢˜...é¡µç 
                r'^(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+ç« \s*.+?)\s*\.{2,}\s*(\d+)$',  # ç¬¬Xç«  æ ‡é¢˜...é¡µç 
                r'^(\d+[\.\)]\d*[\.\)]*\s*.+?)\s+(\d+)$',  # 1.1 æ ‡é¢˜ é¡µç 
                # è‹±æ–‡ç« èŠ‚æ ‡é¢˜
                r'^([A-Z][a-zA-Z\s]+)\s*\.{2,}\s*(\d+)$',  # ABSTRACT...1
                # è¶…é“¾æ¥æ ¼å¼
                r'^(.+?)\s*\[(\d+)\]$',       # æ ‡é¢˜ [é¡µç ]
            ]
            
            # æ£€æŸ¥æ ·å¼æ˜¯å¦åƒç›®å½•
            style_name = paragraph.style.name.lower() if paragraph.style and paragraph.style.name else 'normal'
            is_toc_style = any(keyword in style_name for keyword in [
                'toc', 'table', 'content', 'ç›®å½•', 'heading'
            ])
            
            # æ£€æŸ¥æ–‡æœ¬æ˜¯å¦ç¬¦åˆç›®å½•æ¨¡å¼
            for pattern in toc_patterns:
                match = re.match(pattern, text)
                if match:
                    title = match.group(1).strip()
                    page = match.group(2).strip()
                    
                    # è¿‡æ»¤æ˜æ˜¾ä¸æ˜¯ç›®å½•çš„å†…å®¹
                    if len(title) > 100:  # æ ‡é¢˜å¤ªé•¿
                        continue
                    if not page.isdigit() or int(page) > 1000:  # é¡µç ä¸åˆç†
                        continue
                    
                    toc_candidates.append({
                        'paragraph_index': i,
                        'title': title,
                        'page': page,
                        'raw_text': text,
                        'style': paragraph.style.name if paragraph.style and paragraph.style.name else 'Normal',
                        'is_toc_style': is_toc_style,
                        'pattern': pattern
                    })
                    
                    print(f"ğŸ” å¯èƒ½çš„ç›®å½•æ¡ç›® {i}: {text}")
                    print(f"   æ ‡é¢˜: {title}")
                    print(f"   é¡µç : {page}")
                    print(f"   æ ·å¼: {paragraph.style.name if paragraph.style and paragraph.style.name else 'Normal'}")
                    print(f"   TOCæ ·å¼: {is_toc_style}")
                    print()
                    break
        
        # æŸ¥æ‰¾è¿ç»­çš„ç›®å½•åŒºåŸŸ
        if toc_candidates:
            print(f"\nğŸ“Š æ‰¾åˆ° {len(toc_candidates)} ä¸ªå¯èƒ½çš„ç›®å½•æ¡ç›®")
            
            # æŒ‰æ®µè½ç´¢å¼•åˆ†ç»„ï¼ŒæŸ¥æ‰¾è¿ç»­åŒºåŸŸ
            continuous_groups = []
            current_group = [toc_candidates[0]]
            
            for i in range(1, len(toc_candidates)):
                curr = toc_candidates[i]
                prev = toc_candidates[i-1]
                
                # å¦‚æœæ®µè½ç´¢å¼•ç›¸è¿‘ï¼ˆå…è®¸ä¸­é—´æœ‰å°‘é‡ç©ºæ®µè½ï¼‰
                if curr['paragraph_index'] - prev['paragraph_index'] <= 5:
                    current_group.append(curr)
                else:
                    # ä¿å­˜å½“å‰ç»„ï¼Œå¼€å§‹æ–°ç»„
                    if len(current_group) >= 3:  # è‡³å°‘3ä¸ªæ¡ç›®æ‰è®¤ä¸ºæ˜¯ç›®å½•
                        continuous_groups.append(current_group)
                    current_group = [curr]
            
            # æ·»åŠ æœ€åä¸€ç»„
            if len(current_group) >= 3:
                continuous_groups.append(current_group)
            
            print(f"\nğŸ“‹ æ‰¾åˆ° {len(continuous_groups)} ä¸ªè¿ç»­çš„ç›®å½•åŒºåŸŸ:")
            
            for group_idx, group in enumerate(continuous_groups):
                print(f"\nç›®å½•åŒºåŸŸ {group_idx + 1} (å…±{len(group)}ä¸ªæ¡ç›®):")
                print(f"  æ®µè½èŒƒå›´: {group[0]['paragraph_index']} - {group[-1]['paragraph_index']}")
                
                for entry in group[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªæ¡ç›®
                    print(f"    {entry['title']} -> ç¬¬{entry['page']}é¡µ")
                
                if len(group) > 5:
                    print(f"    ... è¿˜æœ‰ {len(group) - 5} ä¸ªæ¡ç›®")
        
        else:
            print("âŒ æœªæ‰¾åˆ°ç¬¦åˆç›®å½•æ¨¡å¼çš„å†…å®¹")
            
            # å°è¯•æŸ¥æ‰¾ä¸€äº›å¸¸è§çš„ç›®å½•å¼€å§‹æ ‡è®°
            print("\nğŸ” æŸ¥æ‰¾å¯èƒ½çš„ç›®å½•å¼€å§‹æ ‡è®°:")
            for i, paragraph in enumerate(doc.paragraphs[:50], 1):  # åªæ£€æŸ¥å‰50æ®µ
                text = paragraph.text.strip().lower()
                if any(keyword in text for keyword in ['ç›®å½•', 'contents', 'table of contents', 'ç›®ã€€å½•']):
                    print(f"   æ®µè½ {i}: {paragraph.text}")
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def main():
    # åˆ†ææ–‡æ¡£
    test_files = [
        "data/input/1_è®¡ç®—æœºåº”ç”¨æŠ€æœ¯_17211204005-è‹æ…§å©§-åŸºäºMLPå’ŒSepCNNæ¨¡å‹çš„è—æ–‡æ–‡æœ¬åˆ†ç±»ç ”ç©¶ä¸å®ç°-è®¡ç®—æœºåº”ç”¨æŠ€æœ¯-ç¾¤è¯º.docx",
        "data/input/è®¡ç®—æœºåº”ç”¨æŠ€æœ¯_test1.docx"
    ]
    
    for file_path in test_files:
        find_real_toc_content(file_path)
        print("\n" + "="*80 + "\n")

if __name__ == "__main__":
    main()
